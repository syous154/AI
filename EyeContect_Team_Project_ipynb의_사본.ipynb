{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syous154/AI/blob/main/EyeContect_Team_Project_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<아이컨택> Team Project\n",
        "## 이미지 분류를 통한 제주도 여행지 추천\n",
        "##### #include : 전혜지 박서희 심영민 이재훈 정다연"
      ],
      "metadata": {
        "id": "13atYMOCvgpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경 설정\n",
        "\n",
        "*   구글 드라이브 마운트\n",
        "*   필요한 라이브러리 import\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2oHy62ZUwCyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqANDC0TJEg5",
        "outputId": "2f641ade-c650-4d0a-d902-0bd04292384b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "#!pip install tensorflow\n",
        "#!pip install tensorflow==2.8\n"
      ],
      "metadata": {
        "id": "vh2FIkNXx3a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xzwJxP6JSt5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b80c7ed3-27ed-4d35-b6cc-ded5d82f69ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#필요한 라이브러리 import\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import glob\n",
        "from PIL import Image\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##여행 선호도 시각화\n",
        "\n",
        "*   여행지를 제주도로 선정한 이유\n",
        "*   전체 만족도 시각화\n",
        "\n"
      ],
      "metadata": {
        "id": "VgRGXyHVuMpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/새 폴더/여행지별_관광여행_전반적_만족도_20220816224138 (1).csv\",encoding = \"CP949\")\n",
        "df.drop('통계분류(2)',axis = 1,inplace = True)\n",
        "df.columns = list(df.iloc[0][:])\n",
        "df = df.drop(df.index[0])\n",
        "df=df.transpose()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkHWb5S2uSm6",
        "outputId": "2d636da9-0f57-43c3-f91a-c064277c2c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           1     2     3     4     5     6     7     8     9     10  ...  \\\n",
              "통계분류(1)    전체    성별    성별    연령    연령    연령    연령    연령    연령    연령  ...   \n",
              "서울       78.7  78.4  78.9  77.5  79.9  78.5  78.5  77.5    75  82.4  ...   \n",
              "부산       80.5  79.7  81.3  80.8  81.8  79.6  79.9  79.1  80.7  80.6  ...   \n",
              "대구         76  74.3  77.3  77.5  79.2  77.2  73.5  73.1  75.7  74.8  ...   \n",
              "인천       78.1  78.3  77.9  80.3  78.5  78.9  78.8  77.1  76.8  73.6  ...   \n",
              "\n",
              "           22    23    24    25    26    27    28    29    30    31  \n",
              "통계분류(1)  가구원수  가구원수  가구원수  가구소득  가구소득  가구소득  가구소득  가구소득  가구소득  가구소득  \n",
              "서울       80.2  78.8  78.4  81.1  78.6  77.6  78.3  77.9  79.5  78.9  \n",
              "부산       80.3  79.6  80.7  84.7  80.5  80.6  79.7  78.9  79.2  82.9  \n",
              "대구       79.2  76.6    75  76.1  76.1  79.1  76.4    73  75.5  77.5  \n",
              "인천       78.1  78.3    78  79.9  77.9  80.2  77.4  80.4  77.7  76.9  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36164a37-2e89-499a-b9ac-91f39194931a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>통계분류(1)</th>\n",
              "      <td>전체</td>\n",
              "      <td>성별</td>\n",
              "      <td>성별</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>연령</td>\n",
              "      <td>...</td>\n",
              "      <td>가구원수</td>\n",
              "      <td>가구원수</td>\n",
              "      <td>가구원수</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "      <td>가구소득</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>서울</th>\n",
              "      <td>78.7</td>\n",
              "      <td>78.4</td>\n",
              "      <td>78.9</td>\n",
              "      <td>77.5</td>\n",
              "      <td>79.9</td>\n",
              "      <td>78.5</td>\n",
              "      <td>78.5</td>\n",
              "      <td>77.5</td>\n",
              "      <td>75</td>\n",
              "      <td>82.4</td>\n",
              "      <td>...</td>\n",
              "      <td>80.2</td>\n",
              "      <td>78.8</td>\n",
              "      <td>78.4</td>\n",
              "      <td>81.1</td>\n",
              "      <td>78.6</td>\n",
              "      <td>77.6</td>\n",
              "      <td>78.3</td>\n",
              "      <td>77.9</td>\n",
              "      <td>79.5</td>\n",
              "      <td>78.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>부산</th>\n",
              "      <td>80.5</td>\n",
              "      <td>79.7</td>\n",
              "      <td>81.3</td>\n",
              "      <td>80.8</td>\n",
              "      <td>81.8</td>\n",
              "      <td>79.6</td>\n",
              "      <td>79.9</td>\n",
              "      <td>79.1</td>\n",
              "      <td>80.7</td>\n",
              "      <td>80.6</td>\n",
              "      <td>...</td>\n",
              "      <td>80.3</td>\n",
              "      <td>79.6</td>\n",
              "      <td>80.7</td>\n",
              "      <td>84.7</td>\n",
              "      <td>80.5</td>\n",
              "      <td>80.6</td>\n",
              "      <td>79.7</td>\n",
              "      <td>78.9</td>\n",
              "      <td>79.2</td>\n",
              "      <td>82.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>대구</th>\n",
              "      <td>76</td>\n",
              "      <td>74.3</td>\n",
              "      <td>77.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>79.2</td>\n",
              "      <td>77.2</td>\n",
              "      <td>73.5</td>\n",
              "      <td>73.1</td>\n",
              "      <td>75.7</td>\n",
              "      <td>74.8</td>\n",
              "      <td>...</td>\n",
              "      <td>79.2</td>\n",
              "      <td>76.6</td>\n",
              "      <td>75</td>\n",
              "      <td>76.1</td>\n",
              "      <td>76.1</td>\n",
              "      <td>79.1</td>\n",
              "      <td>76.4</td>\n",
              "      <td>73</td>\n",
              "      <td>75.5</td>\n",
              "      <td>77.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>인천</th>\n",
              "      <td>78.1</td>\n",
              "      <td>78.3</td>\n",
              "      <td>77.9</td>\n",
              "      <td>80.3</td>\n",
              "      <td>78.5</td>\n",
              "      <td>78.9</td>\n",
              "      <td>78.8</td>\n",
              "      <td>77.1</td>\n",
              "      <td>76.8</td>\n",
              "      <td>73.6</td>\n",
              "      <td>...</td>\n",
              "      <td>78.1</td>\n",
              "      <td>78.3</td>\n",
              "      <td>78</td>\n",
              "      <td>79.9</td>\n",
              "      <td>77.9</td>\n",
              "      <td>80.2</td>\n",
              "      <td>77.4</td>\n",
              "      <td>80.4</td>\n",
              "      <td>77.7</td>\n",
              "      <td>76.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36164a37-2e89-499a-b9ac-91f39194931a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36164a37-2e89-499a-b9ac-91f39194931a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36164a37-2e89-499a-b9ac-91f39194931a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# warning메시지 무시\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "bdZR7F1vuTCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나눔바른고딕 폰트 설치 - [런타임 다시 시작]되면 폰트를 다시 설치해야 한글이 보입니다.\n",
        "!apt-get install fonts-nanum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr4Bv9V1up7P",
        "outputId": "a967b69e-34b5-49e9-de6b-52babf41b77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 2s (4,401 kB/s)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155654 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글폰트 설치하기 위해 필요함\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "fm.fontManager.addfont('/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf')\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "plt.rcParams['font.family'] = \"NanumBarunGothic\"\n",
        "plt.rcParams['axes.unicode_minus']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQikInNWuamc",
        "outputId": "cb48d59b-f9de-4982-dbc3-c13ca1d3f7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0b771f33a764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfontManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sudo apt-get install -y fonts-nanum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36maddfont\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafmlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft2font\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFT2Font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttfFontProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttflist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "arr = pd.to_numeric(df.iloc[1:][1])\n",
        "arr =arr.sort_values()\n",
        "arr_y = arr.values\n",
        "arr_x = np.array(arr.keys())"
      ],
      "metadata": {
        "id": "_XySM5vBuuOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette('cool',len(arr))\n",
        "plt.figure(figsize = (13,8))\n",
        "plt.title(\"여행지별 전반적 만족도\",size = 20)\n",
        "plt.ylim(60,90)\n",
        "arr.plot(kind = 'bar',color = colors)\n",
        "plt.xticks(rotation = 0,size = 12)\n",
        "for i in range(len(arr_x)):\n",
        "  plt.text(i,arr_y[i],arr_y[i],horizontalalignment='center',verticalalignment='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS-nG-AS32bl",
        "outputId": "e483619b-58e5-4780-e59e-8c87af77c109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##이미지 전처리\n",
        "\n",
        "\n",
        "*   카테고리 리스트 생성\n",
        "*   X에 image, Y에 label을 넣어 라벨링\n",
        "*   이미지 사이즈 및 스케일 조정 작업\n",
        "*   train/test set 나눔\n"
      ],
      "metadata": {
        "id": "TzxIGo1BwLHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVXE_UVJS2E"
      },
      "outputs": [],
      "source": [
        "caltech_dir = \"/content/drive/MyDrive/project_data\" #img파일 경로\n",
        "categories = [\"낚시\",\"농장\", \"동굴\",\"레일바이크\",\"미로\", \"미술관\",\"민속촌\",\n",
        "              \"바다\",\"사찰\", \"산\",\"서핑\",\"섬\",\"성당\",\"숲\",\"스쿠버다이빙\",\"승마\",\n",
        "              \"역사\",\"요트\", \"자동차\",\"잠수함\",\"장성\",\"정원\",\"지질\",\n",
        "              \"짚라인\",\"차\",\"초콜릿\",\"카누\",\"카트\",\"캐릭터\",\"패러글라이딩\",\n",
        "              \"폭포\",\"피아노\",\"해녀\"] #모든 카테고리\n",
        "\n",
        "nb_classes = len(categories) #카테고리 개수\n",
        "\n",
        "image_w = 128 #이미지 가로\n",
        "image_h = 128 #이미지 세로\n",
        "\n",
        "pixels = image_h * image_w *3 #이미지 픽셀\n",
        "\n",
        "X = [] # feature\n",
        "Y = [] # taget\n",
        "\n",
        "#라벨링, 이미지 dir만들어줌\n",
        "for idx,cat in enumerate(categories):\n",
        "  label = [0 for i in range(nb_classes)]\n",
        "  label[idx] = 1\n",
        "\n",
        "  image_dir = caltech_dir +\"/\" + cat\n",
        "  files = glob.glob(image_dir+\"/*.jpg\")\n",
        "\n",
        "  for i,f in enumerate(files):\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w,image_h))\n",
        "    data = np.asarray(img).astype('float32')/255\n",
        "    X.append(data)\n",
        "    Y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "#train과 test set으로 나눔\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모델 생성\n",
        "\n",
        "*   model0 : 기본 모델 설명\n",
        "*   model1 : 은닉층 추가\n",
        "*   model2 : 컨볼루션, 폴링 레이어 추가\n",
        "*   model3 : inceptionV3 임베딩\n"
      ],
      "metadata": {
        "id": "Q3EziYUowUIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(0)CNN모델"
      ],
      "metadata": {
        "id": "eGkKQnwRr9pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es9hwCNE1v67",
        "outputId": "81059d6d-55d1-440c-f395-394eb1c4764d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 71.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.47.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.1\n",
            "    Uninstalling tensorflow-2.9.1:\n",
            "      Successfully uninstalled tensorflow-2.9.1\n",
            "Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 11s (40.4 MB/s)\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155654 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model0 생성\n",
        "model0 = keras.Sequential()\n",
        "model0.add(keras.layers.Conv2D(32,(3,3),padding = \"same\",input_shape = X_train.shape[1:],activation = 'relu'))\n",
        "model0.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model0.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model0.add(keras.layers.Flatten())\n",
        "\n",
        "model0.add(keras.layers.Dense(128,activation = 'relu'))\n",
        "model0.add(keras.layers.Dense(64,activation = 'relu'))\n",
        "\n",
        "model0.add(keras.layers.Dense(nb_classes,activation = 'softmax'))\n",
        "\n",
        "# model0 요약\n",
        "model0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc0skmLxsBuU",
        "outputId": "c4553d6b-cb0a-4fcc-92ca-7b3b2f3b9032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 33)                2145      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,788,641\n",
            "Trainable params: 16,788,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model0 compile\n",
        "model0.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T2jPECvvsf63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train데이터로 학습시킴\n",
        "history = model0.fit(X_train,Y_train,epochs = 30,validation_split=0.25)"
      ],
      "metadata": {
        "id": "kMka9tieslcq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b21ee16-6022-4812-9293-cb09ee19370f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "159/159 [==============================] - 4s 22ms/step - loss: 187.2042 - accuracy: 0.0670 - val_loss: 3.3764 - val_accuracy: 0.0940\n",
            "Epoch 2/30\n",
            "159/159 [==============================] - 4s 23ms/step - loss: 3.2524 - accuracy: 0.1313 - val_loss: 3.2700 - val_accuracy: 0.1277\n",
            "Epoch 3/30\n",
            "159/159 [==============================] - 4s 24ms/step - loss: 2.8988 - accuracy: 0.2055 - val_loss: 3.3372 - val_accuracy: 0.1603\n",
            "Epoch 4/30\n",
            "159/159 [==============================] - 4s 24ms/step - loss: 2.5445 - accuracy: 0.2887 - val_loss: 3.3618 - val_accuracy: 0.1585\n",
            "Epoch 5/30\n",
            "159/159 [==============================] - 4s 26ms/step - loss: 2.2165 - accuracy: 0.3806 - val_loss: 3.4409 - val_accuracy: 0.1697\n",
            "Epoch 6/30\n",
            "159/159 [==============================] - 4s 27ms/step - loss: 1.9086 - accuracy: 0.4500 - val_loss: 3.5343 - val_accuracy: 0.2011\n",
            "Epoch 7/30\n",
            "159/159 [==============================] - 4s 25ms/step - loss: 1.5604 - accuracy: 0.5478 - val_loss: 4.0102 - val_accuracy: 0.1886\n",
            "Epoch 8/30\n",
            "159/159 [==============================] - 4s 26ms/step - loss: 1.3952 - accuracy: 0.6068 - val_loss: 4.1832 - val_accuracy: 0.2147\n",
            "Epoch 9/30\n",
            "159/159 [==============================] - 4s 24ms/step - loss: 1.1794 - accuracy: 0.6701 - val_loss: 3.9752 - val_accuracy: 0.2218\n",
            "Epoch 10/30\n",
            "159/159 [==============================] - 3s 20ms/step - loss: 0.9992 - accuracy: 0.7182 - val_loss: 4.4134 - val_accuracy: 0.2147\n",
            "Epoch 11/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.8281 - accuracy: 0.7657 - val_loss: 4.6931 - val_accuracy: 0.2531\n",
            "Epoch 12/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.7062 - accuracy: 0.8097 - val_loss: 5.1663 - val_accuracy: 0.2354\n",
            "Epoch 13/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.7042 - accuracy: 0.8249 - val_loss: 5.2650 - val_accuracy: 0.2265\n",
            "Epoch 14/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.4952 - accuracy: 0.8695 - val_loss: 5.7386 - val_accuracy: 0.2377\n",
            "Epoch 15/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.4453 - accuracy: 0.8837 - val_loss: 5.5123 - val_accuracy: 0.2472\n",
            "Epoch 16/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.4287 - accuracy: 0.8864 - val_loss: 6.1979 - val_accuracy: 0.2348\n",
            "Epoch 17/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.4940 - accuracy: 0.8933 - val_loss: 6.1727 - val_accuracy: 0.2478\n",
            "Epoch 18/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.3569 - accuracy: 0.9051 - val_loss: 6.6172 - val_accuracy: 0.2295\n",
            "Epoch 19/30\n",
            "159/159 [==============================] - 3s 21ms/step - loss: 0.3156 - accuracy: 0.9255 - val_loss: 6.6775 - val_accuracy: 0.2572\n",
            "Epoch 20/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.2565 - accuracy: 0.9341 - val_loss: 6.7346 - val_accuracy: 0.2484\n",
            "Epoch 21/30\n",
            "159/159 [==============================] - 3s 18ms/step - loss: 0.3316 - accuracy: 0.9282 - val_loss: 7.0426 - val_accuracy: 0.2336\n",
            "Epoch 22/30\n",
            "159/159 [==============================] - 4s 24ms/step - loss: 0.4079 - accuracy: 0.9140 - val_loss: 7.9117 - val_accuracy: 0.2401\n",
            "Epoch 23/30\n",
            " 25/159 [===>..........................] - ETA: 3s - loss: 0.4501 - accuracy: 0.9062"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f5e2dda512db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train데이터로 학습시킴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#손실, 정확도\n",
        "test_loss,test_acc = model0.evaluate(X_test,Y_test)\n",
        "print('\\n테스트 정확도:', test_acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bDX_AXwsvpn",
        "outputId": "49da38f2-95e3-4ee0-8248-9b4b8067df67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 8ms/step - loss: 6.3175 - accuracy: 0.3638\n",
            "\n",
            "테스트 정확도: 36.37976944446564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'], linewidth=\"2\")\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy Trend')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x0HBG2KJtXXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(1) 은닉층 추가 모델"
      ],
      "metadata": {
        "id": "rYjvOdqR2fj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model1 생성\n",
        "model1 = keras.Sequential()\n",
        "model1.add(keras.layers.Conv2D(32,(3,3),padding = \"same\",input_shape = X_train.shape[1:],activation = 'relu'))\n",
        "model1.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model1.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model1.add(keras.layers.Conv2D(64,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model1.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model1.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model1.add(keras.layers.Flatten())\n",
        "\n",
        "model1.add(keras.layers.Dense(1024,activation = 'relu'))\n",
        "model1.add(keras.layers.Dense(512,activation = 'relu'))\n",
        "model1.add(keras.layers.Dense(256,activation = 'relu'))\n",
        "model1.add(keras.layers.Dense(128,activation = 'relu'))\n",
        "model1.add(keras.layers.Dense(64,activation = 'relu'))\n",
        "\n",
        "\n",
        "model1.add(keras.layers.Dense(nb_classes,activation = 'softmax'))\n",
        "\n",
        "# model1 요약\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "i8TH8O6yzimk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model compile\n",
        "model1.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rt1h_aE6tJ_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv__RoBCJTEI"
      },
      "outputs": [],
      "source": [
        "# train데이터로 학습시킴\n",
        "history = model1.fit(X_train,Y_train,batch_size = 32,epochs = 40,validation_split=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5HCQaj_mm9l"
      },
      "outputs": [],
      "source": [
        "#손실, 정확도\n",
        "test_loss,test_acc = model1.evaluate(X_test,Y_test)\n",
        "print('\\n테스트 정확도:', test_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'], linewidth=\"2\")\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy Trend')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qpBaL1PMtZgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(2) 컨볼루션 레이어, 폴링 레이어 추가 모델"
      ],
      "metadata": {
        "id": "EIfetCoM2m77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUos3Kuelqph"
      },
      "outputs": [],
      "source": [
        "#model2 생성\n",
        "model2 = keras.Sequential()\n",
        "model2.add(keras.layers.Conv2D(32,(3,3),padding = \"same\",input_shape = X_train.shape[1:],activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(64,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(128,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(128,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(256,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(256,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Conv2D(512,(3,3),padding = \"same\",activation = 'relu'))\n",
        "model2.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model2.add(keras.layers.Flatten())\n",
        "model2.add(keras.layers.Dense(128,activation = 'relu'))\n",
        "\n",
        "\n",
        "model2.add(keras.layers.Dense(nb_classes,activation = 'softmax'))\n",
        "\n",
        "# model2 요약\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model compile\n",
        "model2.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vEUPSFEmtRk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train데이터로 학습시킴\n",
        "history = model2.fit(X_train,Y_train,batch_size = 32,epochs = 50,validation_split=0.25)"
      ],
      "metadata": {
        "id": "LPKzT_uT01_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#손실, 정확도\n",
        "test_loss,test_acc = model2.evaluate(X_test,Y_test)\n",
        "print('\\n테스트 정확도:', test_acc*100)"
      ],
      "metadata": {
        "id": "8Sp6n1ZLz1-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'], linewidth=\"2\")\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy Trend')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J_i1JimvkVD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(3)inceptionV3 임베딩"
      ],
      "metadata": {
        "id": "9ZVFkjgi30KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import models, layers\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "pYlyMTLi6A6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = InceptionV3(input_shape=(128, 128, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "2LYfwM0e6Hsy",
        "outputId": "deb9f756-c36d-43b6-8c3c-25c1b48ac470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 63, 63, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 63, 63, 32)  96          ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 63, 63, 32)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 61, 61, 32)   9216        ['activation_94[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 61, 61, 32)  96          ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 61, 61, 32)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 61, 61, 64)   18432       ['activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 61, 61, 64)  192         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 61, 61, 64)   0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 30, 30, 64)  0           ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 30, 30, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 30, 30, 80)  240         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 30, 30, 80)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 28, 28, 192)  138240      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 28, 28, 192)  576        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 28, 28, 192)  0           ['batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 192)  0          ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 13, 13, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 13, 13, 64)  192         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 13, 13, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 13, 13, 48)  144         ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 13, 13, 96)  288         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_9 (AveragePo  (None, 13, 13, 192)  0          ['max_pooling2d_5[0][0]']        \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 13, 13, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 13, 13, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 13, 13, 64)  192         ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 13, 13, 64)  192         ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 13, 13, 96)  288         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 13, 13, 32)  96          ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 13, 13, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 13, 13, 256)  0           ['activation_99[0][0]',          \n",
            "                                                                  'activation_101[0][0]',         \n",
            "                                                                  'activation_104[0][0]',         \n",
            "                                                                  'activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 13, 13, 64)  192         ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 13, 13, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 13, 13, 48)  144         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 13, 13, 96)  288         ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_10 (AverageP  (None, 13, 13, 256)  0          ['mixed0[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 13, 13, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 13, 13, 64)  192         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 13, 13, 64)  192         ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 13, 13, 96)  288         ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 13, 13, 64)  192         ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 13, 13, 288)  0           ['activation_106[0][0]',         \n",
            "                                                                  'activation_108[0][0]',         \n",
            "                                                                  'activation_111[0][0]',         \n",
            "                                                                  'activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 13, 13, 64)  192         ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 13, 13, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 13, 13, 48)  144         ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 13, 13, 96)  288         ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_11 (AverageP  (None, 13, 13, 288)  0          ['mixed1[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 13, 13, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 13, 13, 64)  192         ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 13, 13, 64)  192         ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 13, 13, 96)  288         ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 13, 13, 64)  192         ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 13, 13, 288)  0           ['activation_113[0][0]',         \n",
            "                                                                  'activation_115[0][0]',         \n",
            "                                                                  'activation_118[0][0]',         \n",
            "                                                                  'activation_119[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 13, 13, 64)  192         ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 13, 13, 96)  288         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 6, 6, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 6, 6, 96)     82944       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 6, 6, 384)   1152        ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 6, 6, 96)    288         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 6, 6, 96)     0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 6, 6, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 6, 6, 768)    0           ['activation_120[0][0]',         \n",
            "                                                                  'activation_123[0][0]',         \n",
            "                                                                  'max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 6, 6, 128)   384         ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 6, 6, 128)   384         ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 6, 6, 128)   384         ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 6, 6, 128)   384         ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 6, 6, 128)   384         ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 6, 6, 128)   384         ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_12 (AverageP  (None, 6, 6, 768)   0           ['mixed3[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 6, 6, 192)    172032      ['activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 6, 6, 192)    172032      ['activation_131[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_12[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 6, 6, 192)   576         ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 6, 6, 192)   576         ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 6, 6, 192)   576         ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 6, 6, 192)   576         ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 6, 6, 768)    0           ['activation_124[0][0]',         \n",
            "                                                                  'activation_127[0][0]',         \n",
            "                                                                  'activation_132[0][0]',         \n",
            "                                                                  'activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 6, 6, 160)   480         ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 6, 6, 160)   480         ['conv2d_139[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 6, 6, 160)   480         ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 6, 6, 160)   480         ['conv2d_140[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 6, 6, 160)   480         ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 6, 6, 160)   480         ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_13 (AverageP  (None, 6, 6, 768)   0           ['mixed4[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_13[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 6, 6, 192)   576         ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 6, 6, 192)   576         ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 6, 6, 192)   576         ['conv2d_142[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 6, 6, 192)   576         ['conv2d_143[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 6, 6, 768)    0           ['activation_134[0][0]',         \n",
            "                                                                  'activation_137[0][0]',         \n",
            "                                                                  'activation_142[0][0]',         \n",
            "                                                                  'activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 6, 6, 160)   480         ['conv2d_148[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 6, 6, 160)   480         ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 6, 6, 160)   480         ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 6, 6, 160)   480         ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 6, 6, 160)   480         ['conv2d_146[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 6, 6, 160)   480         ['conv2d_151[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_14 (AverageP  (None, 6, 6, 768)   0           ['mixed5[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_14[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 6, 6, 192)   576         ['conv2d_144[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 6, 6, 192)   576         ['conv2d_147[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 6, 6, 192)   576         ['conv2d_152[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 6, 6, 192)   576         ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 6, 6, 768)    0           ['activation_144[0][0]',         \n",
            "                                                                  'activation_147[0][0]',         \n",
            "                                                                  'activation_152[0][0]',         \n",
            "                                                                  'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 6, 6, 192)   576         ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 6, 6, 192)   576         ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 6, 6, 192)   576         ['conv2d_155[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 6, 6, 192)   576         ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 6, 6, 192)   576         ['conv2d_156[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 6, 6, 192)   576         ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, 6, 6, 768)   0           ['mixed6[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 6, 6, 192)   576         ['conv2d_154[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 6, 6, 192)   576         ['conv2d_157[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 6, 6, 192)   576         ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 6, 6, 192)   576         ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 6, 6, 768)    0           ['activation_154[0][0]',         \n",
            "                                                                  'activation_157[0][0]',         \n",
            "                                                                  'activation_162[0][0]',         \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 6, 6, 192)   576         ['conv2d_166[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 6, 6, 192)   576         ['conv2d_167[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 6, 6, 192)   576         ['conv2d_164[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 6, 6, 192)   576         ['conv2d_168[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 2, 2, 320)    552960      ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 2, 2, 192)    331776      ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 2, 2, 320)   960         ['conv2d_165[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 2, 2, 192)   576         ['conv2d_169[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 2, 2, 320)    0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 2, 2, 192)    0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 2, 2, 1280)   0           ['activation_165[0][0]',         \n",
            "                                                                  'activation_169[0][0]',         \n",
            "                                                                  'max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 2, 2, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 2, 2, 448)   1344        ['conv2d_174[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 2, 2, 448)    0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 2, 2, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 2, 2, 384)    1548288     ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 2, 2, 384)   1152        ['conv2d_171[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 2, 2, 384)   1152        ['conv2d_175[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_16 (AverageP  (None, 2, 2, 1280)  0           ['mixed8[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 2, 2, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 2, 2, 384)   1152        ['conv2d_172[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 2, 2, 384)   1152        ['conv2d_173[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 2, 2, 384)   1152        ['conv2d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 2, 2, 384)   1152        ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 2, 2, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 2, 2, 320)   960         ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_176[0][0]']\n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 2, 2, 192)   576         ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 2, 2, 320)    0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 2, 2, 768)    0           ['activation_172[0][0]',         \n",
            "                                                                  'activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 2, 2, 768)    0           ['activation_176[0][0]',         \n",
            "                                                                  'activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 2, 2, 192)    0           ['batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 2, 2, 2048)   0           ['activation_170[0][0]',         \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate_2[0][0]',          \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 2, 2, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 2, 2, 448)   1344        ['conv2d_183[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 2, 2, 448)    0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 2, 2, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 2, 2, 384)    1548288     ['activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 2, 2, 384)   1152        ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 2, 2, 384)   1152        ['conv2d_184[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 2, 2, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_17 (AverageP  (None, 2, 2, 2048)  0           ['mixed9[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 2, 2, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 2, 2, 384)   1152        ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 2, 2, 384)   1152        ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 2, 2, 384)   1152        ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 2, 2, 384)   1152        ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 2, 2, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 2, 2, 320)   960         ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 2, 2, 384)    0           ['batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 2, 2, 192)   576         ['conv2d_187[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 2, 2, 320)    0           ['batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 2, 2, 768)    0           ['activation_181[0][0]',         \n",
            "                                                                  'activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 2, 2, 768)    0           ['activation_185[0][0]',         \n",
            "                                                                  'activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 2, 2, 192)    0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 2, 2, 2048)   0           ['activation_179[0][0]',         \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_3[0][0]',          \n",
            "                                                                  'activation_187[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_layer = layers.Flatten()(last_output)\n",
        "my_layer = layers.Dense(256, activation='relu')(my_layer)\n",
        "my_layer = layers.Dense(128, activation='relu')(my_layer)\n",
        "my_layer = layers.Dense(nb_classes, activation = 'softmax')(my_layer)"
      ],
      "metadata": {
        "id": "UOIiEu0I6MdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Model(pre_trained_model.input, my_layer)\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CclMMSnExvq0",
        "outputId": "78f2c5d4-d25b-45fc-fd78-13c69f3339f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 63, 63, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 63, 63, 32)  96          ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 63, 63, 32)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 61, 61, 32)   9216        ['activation_94[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 61, 61, 32)  96          ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 61, 61, 32)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 61, 61, 64)   18432       ['activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 61, 61, 64)  192         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 61, 61, 64)   0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 30, 30, 64)  0           ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 30, 30, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 30, 30, 80)  240         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 30, 30, 80)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 28, 28, 192)  138240      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 28, 28, 192)  576        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 28, 28, 192)  0           ['batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 192)  0          ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 13, 13, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 13, 13, 64)  192         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 13, 13, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 13, 13, 48)  144         ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 13, 13, 96)  288         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_9 (AveragePo  (None, 13, 13, 192)  0          ['max_pooling2d_5[0][0]']        \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 13, 13, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 13, 13, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 13, 13, 64)  192         ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 13, 13, 64)  192         ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 13, 13, 96)  288         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 13, 13, 32)  96          ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 13, 13, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 13, 13, 256)  0           ['activation_99[0][0]',          \n",
            "                                                                  'activation_101[0][0]',         \n",
            "                                                                  'activation_104[0][0]',         \n",
            "                                                                  'activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 13, 13, 64)  192         ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 13, 13, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 13, 13, 48)  144         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 13, 13, 96)  288         ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_10 (AverageP  (None, 13, 13, 256)  0          ['mixed0[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 13, 13, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 13, 13, 64)  192         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 13, 13, 64)  192         ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 13, 13, 96)  288         ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 13, 13, 64)  192         ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 13, 13, 288)  0           ['activation_106[0][0]',         \n",
            "                                                                  'activation_108[0][0]',         \n",
            "                                                                  'activation_111[0][0]',         \n",
            "                                                                  'activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 13, 13, 64)  192         ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 13, 13, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 13, 13, 48)  144         ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 13, 13, 96)  288         ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_11 (AverageP  (None, 13, 13, 288)  0          ['mixed1[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 13, 13, 64)   76800       ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 13, 13, 96)   82944       ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 13, 13, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 13, 13, 64)  192         ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 13, 13, 64)  192         ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 13, 13, 96)  288         ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 13, 13, 64)  192         ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 13, 13, 288)  0           ['activation_113[0][0]',         \n",
            "                                                                  'activation_115[0][0]',         \n",
            "                                                                  'activation_118[0][0]',         \n",
            "                                                                  'activation_119[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 13, 13, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 13, 13, 64)  192         ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 13, 13, 64)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 13, 13, 96)   55296       ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 13, 13, 96)  288         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 6, 6, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 6, 6, 96)     82944       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 6, 6, 384)   1152        ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 6, 6, 96)    288         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 6, 6, 96)     0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 6, 6, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 6, 6, 768)    0           ['activation_120[0][0]',         \n",
            "                                                                  'activation_123[0][0]',         \n",
            "                                                                  'max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 6, 6, 128)   384         ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 6, 6, 128)   384         ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 6, 6, 128)   384         ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 6, 6, 128)   384         ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 6, 6, 128)    114688      ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 6, 6, 128)   384         ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 6, 6, 128)   384         ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 6, 6, 128)    0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_12 (AverageP  (None, 6, 6, 768)   0           ['mixed3[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 6, 6, 192)    172032      ['activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 6, 6, 192)    172032      ['activation_131[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_12[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 6, 6, 192)   576         ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 6, 6, 192)   576         ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 6, 6, 192)   576         ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 6, 6, 192)   576         ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 6, 6, 768)    0           ['activation_124[0][0]',         \n",
            "                                                                  'activation_127[0][0]',         \n",
            "                                                                  'activation_132[0][0]',         \n",
            "                                                                  'activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 6, 6, 160)   480         ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 6, 6, 160)   480         ['conv2d_139[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 6, 6, 160)   480         ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 6, 6, 160)   480         ['conv2d_140[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 6, 6, 160)   480         ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 6, 6, 160)   480         ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_13 (AverageP  (None, 6, 6, 768)   0           ['mixed4[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_13[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 6, 6, 192)   576         ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 6, 6, 192)   576         ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 6, 6, 192)   576         ['conv2d_142[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 6, 6, 192)   576         ['conv2d_143[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 6, 6, 768)    0           ['activation_134[0][0]',         \n",
            "                                                                  'activation_137[0][0]',         \n",
            "                                                                  'activation_142[0][0]',         \n",
            "                                                                  'activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 6, 6, 160)   480         ['conv2d_148[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 6, 6, 160)   480         ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 6, 6, 160)   480         ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 6, 6, 160)   480         ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 6, 6, 160)    179200      ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 6, 6, 160)   480         ['conv2d_146[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 6, 6, 160)   480         ['conv2d_151[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 6, 6, 160)    0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_14 (AverageP  (None, 6, 6, 768)   0           ['mixed5[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 6, 6, 192)    215040      ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_14[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 6, 6, 192)   576         ['conv2d_144[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 6, 6, 192)   576         ['conv2d_147[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 6, 6, 192)   576         ['conv2d_152[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 6, 6, 192)   576         ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 6, 6, 768)    0           ['activation_144[0][0]',         \n",
            "                                                                  'activation_147[0][0]',         \n",
            "                                                                  'activation_152[0][0]',         \n",
            "                                                                  'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 6, 6, 192)   576         ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 6, 6, 192)   576         ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 6, 6, 192)   576         ['conv2d_155[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 6, 6, 192)   576         ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 6, 6, 192)   576         ['conv2d_156[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 6, 6, 192)   576         ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, 6, 6, 768)   0           ['mixed6[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 6, 6, 192)    258048      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 6, 6, 192)    147456      ['average_pooling2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 6, 6, 192)   576         ['conv2d_154[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 6, 6, 192)   576         ['conv2d_157[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 6, 6, 192)   576         ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 6, 6, 192)   576         ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 6, 6, 768)    0           ['activation_154[0][0]',         \n",
            "                                                                  'activation_157[0][0]',         \n",
            "                                                                  'activation_162[0][0]',         \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 27648)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          7078144     ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          32896       ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 33)           4257        ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,090,561\n",
            "Trainable params: 7,115,297\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(X_train, Y_train, epochs = 500, validation_split=0.25)"
      ],
      "metadata": {
        "id": "meR6cBudxy3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20573160-10a0-4132-efd3-750199e14860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "159/159 [==============================] - 10s 62ms/step - loss: 0.0273 - accuracy: 0.1824 - val_loss: 0.0272 - val_accuracy: 0.1827\n",
            "Epoch 2/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0270 - accuracy: 0.2002 - val_loss: 0.0272 - val_accuracy: 0.1916\n",
            "Epoch 3/500\n",
            "159/159 [==============================] - 9s 58ms/step - loss: 0.0268 - accuracy: 0.2055 - val_loss: 0.0269 - val_accuracy: 0.2111\n",
            "Epoch 4/500\n",
            "159/159 [==============================] - 8s 50ms/step - loss: 0.0267 - accuracy: 0.2094 - val_loss: 0.0269 - val_accuracy: 0.2105\n",
            "Epoch 5/500\n",
            "159/159 [==============================] - 8s 50ms/step - loss: 0.0265 - accuracy: 0.2211 - val_loss: 0.0268 - val_accuracy: 0.2082\n",
            "Epoch 6/500\n",
            "159/159 [==============================] - 9s 58ms/step - loss: 0.0265 - accuracy: 0.2222 - val_loss: 0.0266 - val_accuracy: 0.2247\n",
            "Epoch 7/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0263 - accuracy: 0.2220 - val_loss: 0.0266 - val_accuracy: 0.2235\n",
            "Epoch 8/500\n",
            "159/159 [==============================] - 8s 50ms/step - loss: 0.0262 - accuracy: 0.2276 - val_loss: 0.0265 - val_accuracy: 0.2277\n",
            "Epoch 9/500\n",
            "159/159 [==============================] - 8s 50ms/step - loss: 0.0260 - accuracy: 0.2428 - val_loss: 0.0262 - val_accuracy: 0.2478\n",
            "Epoch 10/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0259 - accuracy: 0.2445 - val_loss: 0.0262 - val_accuracy: 0.2395\n",
            "Epoch 11/500\n",
            "159/159 [==============================] - 9s 57ms/step - loss: 0.0259 - accuracy: 0.2487 - val_loss: 0.0262 - val_accuracy: 0.2448\n",
            "Epoch 12/500\n",
            "159/159 [==============================] - 9s 57ms/step - loss: 0.0257 - accuracy: 0.2550 - val_loss: 0.0262 - val_accuracy: 0.2318\n",
            "Epoch 13/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0256 - accuracy: 0.2573 - val_loss: 0.0259 - val_accuracy: 0.2519\n",
            "Epoch 14/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0256 - accuracy: 0.2591 - val_loss: 0.0259 - val_accuracy: 0.2596\n",
            "Epoch 15/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0257 - accuracy: 0.2593 - val_loss: 0.0260 - val_accuracy: 0.2519\n",
            "Epoch 16/500\n",
            "159/159 [==============================] - 6s 37ms/step - loss: 0.0254 - accuracy: 0.2680 - val_loss: 0.0260 - val_accuracy: 0.2584\n",
            "Epoch 17/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0254 - accuracy: 0.2733 - val_loss: 0.0258 - val_accuracy: 0.2590\n",
            "Epoch 18/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0253 - accuracy: 0.2820 - val_loss: 0.0258 - val_accuracy: 0.2643\n",
            "Epoch 19/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0252 - accuracy: 0.2865 - val_loss: 0.0255 - val_accuracy: 0.2685\n",
            "Epoch 20/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0251 - accuracy: 0.2816 - val_loss: 0.0259 - val_accuracy: 0.2525\n",
            "Epoch 21/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0251 - accuracy: 0.2861 - val_loss: 0.0254 - val_accuracy: 0.2886\n",
            "Epoch 22/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0250 - accuracy: 0.2948 - val_loss: 0.0256 - val_accuracy: 0.2726\n",
            "Epoch 23/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0248 - accuracy: 0.2997 - val_loss: 0.0255 - val_accuracy: 0.2880\n",
            "Epoch 24/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0247 - accuracy: 0.3041 - val_loss: 0.0251 - val_accuracy: 0.3016\n",
            "Epoch 25/500\n",
            "159/159 [==============================] - 6s 35ms/step - loss: 0.0247 - accuracy: 0.3080 - val_loss: 0.0253 - val_accuracy: 0.2827\n",
            "Epoch 26/500\n",
            "159/159 [==============================] - 6s 35ms/step - loss: 0.0245 - accuracy: 0.3124 - val_loss: 0.0252 - val_accuracy: 0.2880\n",
            "Epoch 27/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0244 - accuracy: 0.3141 - val_loss: 0.0257 - val_accuracy: 0.2703\n",
            "Epoch 28/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0243 - accuracy: 0.3183 - val_loss: 0.0250 - val_accuracy: 0.2980\n",
            "Epoch 29/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0243 - accuracy: 0.3226 - val_loss: 0.0248 - val_accuracy: 0.3081\n",
            "Epoch 30/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0242 - accuracy: 0.3307 - val_loss: 0.0246 - val_accuracy: 0.3199\n",
            "Epoch 31/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0240 - accuracy: 0.3319 - val_loss: 0.0247 - val_accuracy: 0.3128\n",
            "Epoch 32/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0241 - accuracy: 0.3329 - val_loss: 0.0248 - val_accuracy: 0.3087\n",
            "Epoch 33/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0240 - accuracy: 0.3335 - val_loss: 0.0251 - val_accuracy: 0.3022\n",
            "Epoch 34/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0238 - accuracy: 0.3479 - val_loss: 0.0245 - val_accuracy: 0.3282\n",
            "Epoch 35/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0238 - accuracy: 0.3408 - val_loss: 0.0243 - val_accuracy: 0.3270\n",
            "Epoch 36/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0238 - accuracy: 0.3384 - val_loss: 0.0244 - val_accuracy: 0.3300\n",
            "Epoch 37/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0236 - accuracy: 0.3475 - val_loss: 0.0245 - val_accuracy: 0.3164\n",
            "Epoch 38/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0235 - accuracy: 0.3510 - val_loss: 0.0248 - val_accuracy: 0.3087\n",
            "Epoch 39/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0235 - accuracy: 0.3496 - val_loss: 0.0242 - val_accuracy: 0.3347\n",
            "Epoch 40/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0234 - accuracy: 0.3589 - val_loss: 0.0243 - val_accuracy: 0.3223\n",
            "Epoch 41/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0233 - accuracy: 0.3613 - val_loss: 0.0243 - val_accuracy: 0.3300\n",
            "Epoch 42/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0233 - accuracy: 0.3634 - val_loss: 0.0239 - val_accuracy: 0.3442\n",
            "Epoch 43/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0231 - accuracy: 0.3674 - val_loss: 0.0245 - val_accuracy: 0.3152\n",
            "Epoch 44/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0231 - accuracy: 0.3672 - val_loss: 0.0241 - val_accuracy: 0.3347\n",
            "Epoch 45/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0232 - accuracy: 0.3737 - val_loss: 0.0238 - val_accuracy: 0.3536\n",
            "Epoch 46/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0231 - accuracy: 0.3658 - val_loss: 0.0238 - val_accuracy: 0.3495\n",
            "Epoch 47/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0229 - accuracy: 0.3721 - val_loss: 0.0236 - val_accuracy: 0.3412\n",
            "Epoch 48/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0228 - accuracy: 0.3814 - val_loss: 0.0239 - val_accuracy: 0.3519\n",
            "Epoch 49/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0228 - accuracy: 0.3723 - val_loss: 0.0238 - val_accuracy: 0.3566\n",
            "Epoch 50/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0227 - accuracy: 0.3826 - val_loss: 0.0237 - val_accuracy: 0.3471\n",
            "Epoch 51/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0226 - accuracy: 0.3843 - val_loss: 0.0238 - val_accuracy: 0.3442\n",
            "Epoch 52/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0225 - accuracy: 0.3877 - val_loss: 0.0236 - val_accuracy: 0.3560\n",
            "Epoch 53/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0225 - accuracy: 0.3893 - val_loss: 0.0236 - val_accuracy: 0.3625\n",
            "Epoch 54/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0225 - accuracy: 0.3836 - val_loss: 0.0241 - val_accuracy: 0.3389\n",
            "Epoch 55/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0224 - accuracy: 0.3930 - val_loss: 0.0235 - val_accuracy: 0.3625\n",
            "Epoch 56/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0224 - accuracy: 0.3924 - val_loss: 0.0234 - val_accuracy: 0.3596\n",
            "Epoch 57/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0223 - accuracy: 0.3948 - val_loss: 0.0234 - val_accuracy: 0.3666\n",
            "Epoch 58/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0223 - accuracy: 0.4037 - val_loss: 0.0231 - val_accuracy: 0.3856\n",
            "Epoch 59/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0221 - accuracy: 0.3993 - val_loss: 0.0231 - val_accuracy: 0.3743\n",
            "Epoch 60/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0222 - accuracy: 0.3954 - val_loss: 0.0233 - val_accuracy: 0.3726\n",
            "Epoch 61/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0221 - accuracy: 0.4041 - val_loss: 0.0231 - val_accuracy: 0.3808\n",
            "Epoch 62/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0220 - accuracy: 0.4021 - val_loss: 0.0233 - val_accuracy: 0.3755\n",
            "Epoch 63/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0219 - accuracy: 0.4080 - val_loss: 0.0239 - val_accuracy: 0.3501\n",
            "Epoch 64/500\n",
            "159/159 [==============================] - 7s 46ms/step - loss: 0.0220 - accuracy: 0.4161 - val_loss: 0.0235 - val_accuracy: 0.3637\n",
            "Epoch 65/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0218 - accuracy: 0.4145 - val_loss: 0.0235 - val_accuracy: 0.3714\n",
            "Epoch 66/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0218 - accuracy: 0.4102 - val_loss: 0.0231 - val_accuracy: 0.3785\n",
            "Epoch 67/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0216 - accuracy: 0.4204 - val_loss: 0.0231 - val_accuracy: 0.3755\n",
            "Epoch 68/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0218 - accuracy: 0.4121 - val_loss: 0.0234 - val_accuracy: 0.3702\n",
            "Epoch 69/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0217 - accuracy: 0.4127 - val_loss: 0.0229 - val_accuracy: 0.3891\n",
            "Epoch 70/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0215 - accuracy: 0.4252 - val_loss: 0.0229 - val_accuracy: 0.3838\n",
            "Epoch 71/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0215 - accuracy: 0.4210 - val_loss: 0.0230 - val_accuracy: 0.3850\n",
            "Epoch 72/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0215 - accuracy: 0.4204 - val_loss: 0.0230 - val_accuracy: 0.3743\n",
            "Epoch 73/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0215 - accuracy: 0.4214 - val_loss: 0.0229 - val_accuracy: 0.3832\n",
            "Epoch 74/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0213 - accuracy: 0.4271 - val_loss: 0.0230 - val_accuracy: 0.3921\n",
            "Epoch 75/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0214 - accuracy: 0.4242 - val_loss: 0.0232 - val_accuracy: 0.3909\n",
            "Epoch 76/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0212 - accuracy: 0.4346 - val_loss: 0.0227 - val_accuracy: 0.3915\n",
            "Epoch 77/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0211 - accuracy: 0.4378 - val_loss: 0.0228 - val_accuracy: 0.3974\n",
            "Epoch 78/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0210 - accuracy: 0.4344 - val_loss: 0.0234 - val_accuracy: 0.3761\n",
            "Epoch 79/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0211 - accuracy: 0.4394 - val_loss: 0.0226 - val_accuracy: 0.3956\n",
            "Epoch 80/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0210 - accuracy: 0.4392 - val_loss: 0.0226 - val_accuracy: 0.3968\n",
            "Epoch 81/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0209 - accuracy: 0.4394 - val_loss: 0.0232 - val_accuracy: 0.3808\n",
            "Epoch 82/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0209 - accuracy: 0.4455 - val_loss: 0.0231 - val_accuracy: 0.3761\n",
            "Epoch 83/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0209 - accuracy: 0.4415 - val_loss: 0.0226 - val_accuracy: 0.4004\n",
            "Epoch 84/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0208 - accuracy: 0.4510 - val_loss: 0.0222 - val_accuracy: 0.4163\n",
            "Epoch 85/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0206 - accuracy: 0.4555 - val_loss: 0.0223 - val_accuracy: 0.4110\n",
            "Epoch 86/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0206 - accuracy: 0.4577 - val_loss: 0.0224 - val_accuracy: 0.4092\n",
            "Epoch 87/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0206 - accuracy: 0.4557 - val_loss: 0.0225 - val_accuracy: 0.3998\n",
            "Epoch 88/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0205 - accuracy: 0.4609 - val_loss: 0.0224 - val_accuracy: 0.4075\n",
            "Epoch 89/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0205 - accuracy: 0.4607 - val_loss: 0.0228 - val_accuracy: 0.3897\n",
            "Epoch 90/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0204 - accuracy: 0.4614 - val_loss: 0.0223 - val_accuracy: 0.4098\n",
            "Epoch 91/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0205 - accuracy: 0.4599 - val_loss: 0.0228 - val_accuracy: 0.3933\n",
            "Epoch 92/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0204 - accuracy: 0.4642 - val_loss: 0.0221 - val_accuracy: 0.4216\n",
            "Epoch 93/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0203 - accuracy: 0.4660 - val_loss: 0.0223 - val_accuracy: 0.4069\n",
            "Epoch 94/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0203 - accuracy: 0.4662 - val_loss: 0.0223 - val_accuracy: 0.4092\n",
            "Epoch 95/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0203 - accuracy: 0.4652 - val_loss: 0.0223 - val_accuracy: 0.4098\n",
            "Epoch 96/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0201 - accuracy: 0.4695 - val_loss: 0.0221 - val_accuracy: 0.4169\n",
            "Epoch 97/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0202 - accuracy: 0.4717 - val_loss: 0.0229 - val_accuracy: 0.3850\n",
            "Epoch 98/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0199 - accuracy: 0.4827 - val_loss: 0.0224 - val_accuracy: 0.4086\n",
            "Epoch 99/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0198 - accuracy: 0.4814 - val_loss: 0.0223 - val_accuracy: 0.4134\n",
            "Epoch 100/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0200 - accuracy: 0.4753 - val_loss: 0.0230 - val_accuracy: 0.3980\n",
            "Epoch 101/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0200 - accuracy: 0.4774 - val_loss: 0.0223 - val_accuracy: 0.4134\n",
            "Epoch 102/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0198 - accuracy: 0.4786 - val_loss: 0.0221 - val_accuracy: 0.4240\n",
            "Epoch 103/500\n",
            "159/159 [==============================] - 6s 38ms/step - loss: 0.0196 - accuracy: 0.4900 - val_loss: 0.0219 - val_accuracy: 0.4246\n",
            "Epoch 104/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0196 - accuracy: 0.4900 - val_loss: 0.0224 - val_accuracy: 0.4211\n",
            "Epoch 105/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0197 - accuracy: 0.4816 - val_loss: 0.0220 - val_accuracy: 0.4169\n",
            "Epoch 106/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0196 - accuracy: 0.4914 - val_loss: 0.0222 - val_accuracy: 0.4246\n",
            "Epoch 107/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0195 - accuracy: 0.4964 - val_loss: 0.0219 - val_accuracy: 0.4270\n",
            "Epoch 108/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0195 - accuracy: 0.4930 - val_loss: 0.0220 - val_accuracy: 0.4246\n",
            "Epoch 109/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0195 - accuracy: 0.4938 - val_loss: 0.0230 - val_accuracy: 0.3950\n",
            "Epoch 110/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0192 - accuracy: 0.4987 - val_loss: 0.0220 - val_accuracy: 0.4270\n",
            "Epoch 111/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0193 - accuracy: 0.5009 - val_loss: 0.0221 - val_accuracy: 0.4181\n",
            "Epoch 112/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0193 - accuracy: 0.5001 - val_loss: 0.0219 - val_accuracy: 0.4270\n",
            "Epoch 113/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0194 - accuracy: 0.5001 - val_loss: 0.0221 - val_accuracy: 0.4252\n",
            "Epoch 114/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0193 - accuracy: 0.5050 - val_loss: 0.0220 - val_accuracy: 0.4293\n",
            "Epoch 115/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0190 - accuracy: 0.5137 - val_loss: 0.0221 - val_accuracy: 0.4323\n",
            "Epoch 116/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0190 - accuracy: 0.5106 - val_loss: 0.0220 - val_accuracy: 0.4222\n",
            "Epoch 117/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0191 - accuracy: 0.5107 - val_loss: 0.0225 - val_accuracy: 0.4122\n",
            "Epoch 118/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0189 - accuracy: 0.5190 - val_loss: 0.0217 - val_accuracy: 0.4418\n",
            "Epoch 119/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0188 - accuracy: 0.5139 - val_loss: 0.0219 - val_accuracy: 0.4234\n",
            "Epoch 120/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0189 - accuracy: 0.5178 - val_loss: 0.0221 - val_accuracy: 0.4169\n",
            "Epoch 121/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0189 - accuracy: 0.5204 - val_loss: 0.0216 - val_accuracy: 0.4382\n",
            "Epoch 122/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0187 - accuracy: 0.5163 - val_loss: 0.0226 - val_accuracy: 0.4069\n",
            "Epoch 123/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0188 - accuracy: 0.5178 - val_loss: 0.0218 - val_accuracy: 0.4370\n",
            "Epoch 124/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0186 - accuracy: 0.5246 - val_loss: 0.0216 - val_accuracy: 0.4329\n",
            "Epoch 125/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0187 - accuracy: 0.5228 - val_loss: 0.0220 - val_accuracy: 0.4258\n",
            "Epoch 126/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0186 - accuracy: 0.5277 - val_loss: 0.0214 - val_accuracy: 0.4483\n",
            "Epoch 127/500\n",
            "159/159 [==============================] - 5s 31ms/step - loss: 0.0185 - accuracy: 0.5222 - val_loss: 0.0218 - val_accuracy: 0.4329\n",
            "Epoch 128/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0184 - accuracy: 0.5320 - val_loss: 0.0220 - val_accuracy: 0.4347\n",
            "Epoch 129/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0185 - accuracy: 0.5200 - val_loss: 0.0218 - val_accuracy: 0.4441\n",
            "Epoch 130/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0184 - accuracy: 0.5277 - val_loss: 0.0219 - val_accuracy: 0.4394\n",
            "Epoch 131/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0183 - accuracy: 0.5374 - val_loss: 0.0222 - val_accuracy: 0.4134\n",
            "Epoch 132/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0183 - accuracy: 0.5307 - val_loss: 0.0223 - val_accuracy: 0.4169\n",
            "Epoch 133/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0183 - accuracy: 0.5293 - val_loss: 0.0220 - val_accuracy: 0.4352\n",
            "Epoch 134/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0182 - accuracy: 0.5346 - val_loss: 0.0213 - val_accuracy: 0.4530\n",
            "Epoch 135/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0180 - accuracy: 0.5464 - val_loss: 0.0217 - val_accuracy: 0.4335\n",
            "Epoch 136/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0181 - accuracy: 0.5429 - val_loss: 0.0216 - val_accuracy: 0.4400\n",
            "Epoch 137/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0181 - accuracy: 0.5366 - val_loss: 0.0220 - val_accuracy: 0.4234\n",
            "Epoch 138/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0178 - accuracy: 0.5492 - val_loss: 0.0213 - val_accuracy: 0.4524\n",
            "Epoch 139/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0180 - accuracy: 0.5435 - val_loss: 0.0222 - val_accuracy: 0.4187\n",
            "Epoch 140/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0180 - accuracy: 0.5451 - val_loss: 0.0215 - val_accuracy: 0.4406\n",
            "Epoch 141/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0177 - accuracy: 0.5518 - val_loss: 0.0217 - val_accuracy: 0.4412\n",
            "Epoch 142/500\n",
            "159/159 [==============================] - 6s 36ms/step - loss: 0.0178 - accuracy: 0.5535 - val_loss: 0.0218 - val_accuracy: 0.4358\n",
            "Epoch 143/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0178 - accuracy: 0.5490 - val_loss: 0.0214 - val_accuracy: 0.4429\n",
            "Epoch 144/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0177 - accuracy: 0.5528 - val_loss: 0.0216 - val_accuracy: 0.4423\n",
            "Epoch 145/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0179 - accuracy: 0.5458 - val_loss: 0.0214 - val_accuracy: 0.4518\n",
            "Epoch 146/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0177 - accuracy: 0.5597 - val_loss: 0.0216 - val_accuracy: 0.4471\n",
            "Epoch 147/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0176 - accuracy: 0.5565 - val_loss: 0.0225 - val_accuracy: 0.4175\n",
            "Epoch 148/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0176 - accuracy: 0.5553 - val_loss: 0.0213 - val_accuracy: 0.4577\n",
            "Epoch 149/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0176 - accuracy: 0.5547 - val_loss: 0.0214 - val_accuracy: 0.4459\n",
            "Epoch 150/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0175 - accuracy: 0.5541 - val_loss: 0.0211 - val_accuracy: 0.4613\n",
            "Epoch 151/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0172 - accuracy: 0.5658 - val_loss: 0.0212 - val_accuracy: 0.4595\n",
            "Epoch 152/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0174 - accuracy: 0.5656 - val_loss: 0.0220 - val_accuracy: 0.4347\n",
            "Epoch 153/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0173 - accuracy: 0.5624 - val_loss: 0.0213 - val_accuracy: 0.4524\n",
            "Epoch 154/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0172 - accuracy: 0.5662 - val_loss: 0.0218 - val_accuracy: 0.4494\n",
            "Epoch 155/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0171 - accuracy: 0.5654 - val_loss: 0.0212 - val_accuracy: 0.4660\n",
            "Epoch 156/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0170 - accuracy: 0.5727 - val_loss: 0.0217 - val_accuracy: 0.4429\n",
            "Epoch 157/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0170 - accuracy: 0.5683 - val_loss: 0.0213 - val_accuracy: 0.4630\n",
            "Epoch 158/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0170 - accuracy: 0.5677 - val_loss: 0.0213 - val_accuracy: 0.4477\n",
            "Epoch 159/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0169 - accuracy: 0.5758 - val_loss: 0.0219 - val_accuracy: 0.4270\n",
            "Epoch 160/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0169 - accuracy: 0.5758 - val_loss: 0.0217 - val_accuracy: 0.4512\n",
            "Epoch 161/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0172 - accuracy: 0.5616 - val_loss: 0.0217 - val_accuracy: 0.4418\n",
            "Epoch 162/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0169 - accuracy: 0.5727 - val_loss: 0.0211 - val_accuracy: 0.4690\n",
            "Epoch 163/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0169 - accuracy: 0.5768 - val_loss: 0.0214 - val_accuracy: 0.4554\n",
            "Epoch 164/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0168 - accuracy: 0.5780 - val_loss: 0.0215 - val_accuracy: 0.4494\n",
            "Epoch 165/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0166 - accuracy: 0.5896 - val_loss: 0.0217 - val_accuracy: 0.4429\n",
            "Epoch 166/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0166 - accuracy: 0.5859 - val_loss: 0.0210 - val_accuracy: 0.4595\n",
            "Epoch 167/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0167 - accuracy: 0.5813 - val_loss: 0.0212 - val_accuracy: 0.4577\n",
            "Epoch 168/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0166 - accuracy: 0.5835 - val_loss: 0.0209 - val_accuracy: 0.4737\n",
            "Epoch 169/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0165 - accuracy: 0.5877 - val_loss: 0.0210 - val_accuracy: 0.4619\n",
            "Epoch 170/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0163 - accuracy: 0.5896 - val_loss: 0.0211 - val_accuracy: 0.4601\n",
            "Epoch 171/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0166 - accuracy: 0.5817 - val_loss: 0.0211 - val_accuracy: 0.4654\n",
            "Epoch 172/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0164 - accuracy: 0.5922 - val_loss: 0.0214 - val_accuracy: 0.4583\n",
            "Epoch 173/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0163 - accuracy: 0.5898 - val_loss: 0.0215 - val_accuracy: 0.4465\n",
            "Epoch 174/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0162 - accuracy: 0.5934 - val_loss: 0.0212 - val_accuracy: 0.4624\n",
            "Epoch 175/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0162 - accuracy: 0.6007 - val_loss: 0.0212 - val_accuracy: 0.4589\n",
            "Epoch 176/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0162 - accuracy: 0.5922 - val_loss: 0.0213 - val_accuracy: 0.4565\n",
            "Epoch 177/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0162 - accuracy: 0.5967 - val_loss: 0.0213 - val_accuracy: 0.4559\n",
            "Epoch 178/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0161 - accuracy: 0.5983 - val_loss: 0.0210 - val_accuracy: 0.4672\n",
            "Epoch 179/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0161 - accuracy: 0.6017 - val_loss: 0.0221 - val_accuracy: 0.4406\n",
            "Epoch 180/500\n",
            "159/159 [==============================] - 6s 36ms/step - loss: 0.0159 - accuracy: 0.6019 - val_loss: 0.0210 - val_accuracy: 0.4619\n",
            "Epoch 181/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0158 - accuracy: 0.6068 - val_loss: 0.0215 - val_accuracy: 0.4506\n",
            "Epoch 182/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0163 - accuracy: 0.5938 - val_loss: 0.0211 - val_accuracy: 0.4613\n",
            "Epoch 183/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0159 - accuracy: 0.6097 - val_loss: 0.0210 - val_accuracy: 0.4690\n",
            "Epoch 184/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0158 - accuracy: 0.6111 - val_loss: 0.0211 - val_accuracy: 0.4601\n",
            "Epoch 185/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0157 - accuracy: 0.6090 - val_loss: 0.0211 - val_accuracy: 0.4607\n",
            "Epoch 186/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0157 - accuracy: 0.6095 - val_loss: 0.0209 - val_accuracy: 0.4654\n",
            "Epoch 187/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0158 - accuracy: 0.6090 - val_loss: 0.0214 - val_accuracy: 0.4589\n",
            "Epoch 188/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0155 - accuracy: 0.6162 - val_loss: 0.0214 - val_accuracy: 0.4654\n",
            "Epoch 189/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0156 - accuracy: 0.6228 - val_loss: 0.0212 - val_accuracy: 0.4571\n",
            "Epoch 190/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0156 - accuracy: 0.6090 - val_loss: 0.0218 - val_accuracy: 0.4447\n",
            "Epoch 191/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0155 - accuracy: 0.6188 - val_loss: 0.0209 - val_accuracy: 0.4755\n",
            "Epoch 192/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0156 - accuracy: 0.6135 - val_loss: 0.0213 - val_accuracy: 0.4672\n",
            "Epoch 193/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0154 - accuracy: 0.6222 - val_loss: 0.0210 - val_accuracy: 0.4666\n",
            "Epoch 194/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0154 - accuracy: 0.6159 - val_loss: 0.0210 - val_accuracy: 0.4760\n",
            "Epoch 195/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0154 - accuracy: 0.6182 - val_loss: 0.0213 - val_accuracy: 0.4654\n",
            "Epoch 196/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0153 - accuracy: 0.6220 - val_loss: 0.0210 - val_accuracy: 0.4701\n",
            "Epoch 197/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0152 - accuracy: 0.6235 - val_loss: 0.0215 - val_accuracy: 0.4619\n",
            "Epoch 198/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0153 - accuracy: 0.6188 - val_loss: 0.0211 - val_accuracy: 0.4636\n",
            "Epoch 199/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0153 - accuracy: 0.6237 - val_loss: 0.0216 - val_accuracy: 0.4636\n",
            "Epoch 200/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0152 - accuracy: 0.6275 - val_loss: 0.0219 - val_accuracy: 0.4418\n",
            "Epoch 201/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0151 - accuracy: 0.6306 - val_loss: 0.0211 - val_accuracy: 0.4601\n",
            "Epoch 202/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0148 - accuracy: 0.6379 - val_loss: 0.0209 - val_accuracy: 0.4755\n",
            "Epoch 203/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0151 - accuracy: 0.6297 - val_loss: 0.0218 - val_accuracy: 0.4530\n",
            "Epoch 204/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0154 - accuracy: 0.6151 - val_loss: 0.0211 - val_accuracy: 0.4601\n",
            "Epoch 205/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0149 - accuracy: 0.6405 - val_loss: 0.0211 - val_accuracy: 0.4630\n",
            "Epoch 206/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0150 - accuracy: 0.6304 - val_loss: 0.0212 - val_accuracy: 0.4607\n",
            "Epoch 207/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0149 - accuracy: 0.6320 - val_loss: 0.0207 - val_accuracy: 0.4760\n",
            "Epoch 208/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0148 - accuracy: 0.6395 - val_loss: 0.0216 - val_accuracy: 0.4512\n",
            "Epoch 209/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0150 - accuracy: 0.6324 - val_loss: 0.0224 - val_accuracy: 0.4335\n",
            "Epoch 210/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0147 - accuracy: 0.6399 - val_loss: 0.0208 - val_accuracy: 0.4707\n",
            "Epoch 211/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0144 - accuracy: 0.6490 - val_loss: 0.0224 - val_accuracy: 0.4293\n",
            "Epoch 212/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0148 - accuracy: 0.6373 - val_loss: 0.0219 - val_accuracy: 0.4518\n",
            "Epoch 213/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0146 - accuracy: 0.6395 - val_loss: 0.0210 - val_accuracy: 0.4684\n",
            "Epoch 214/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0147 - accuracy: 0.6391 - val_loss: 0.0212 - val_accuracy: 0.4772\n",
            "Epoch 215/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0145 - accuracy: 0.6470 - val_loss: 0.0213 - val_accuracy: 0.4636\n",
            "Epoch 216/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0143 - accuracy: 0.6529 - val_loss: 0.0211 - val_accuracy: 0.4701\n",
            "Epoch 217/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0144 - accuracy: 0.6498 - val_loss: 0.0215 - val_accuracy: 0.4524\n",
            "Epoch 218/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0146 - accuracy: 0.6464 - val_loss: 0.0214 - val_accuracy: 0.4654\n",
            "Epoch 219/500\n",
            "159/159 [==============================] - 6s 36ms/step - loss: 0.0144 - accuracy: 0.6492 - val_loss: 0.0213 - val_accuracy: 0.4619\n",
            "Epoch 220/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0143 - accuracy: 0.6541 - val_loss: 0.0216 - val_accuracy: 0.4589\n",
            "Epoch 221/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0143 - accuracy: 0.6480 - val_loss: 0.0221 - val_accuracy: 0.4341\n",
            "Epoch 222/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0143 - accuracy: 0.6529 - val_loss: 0.0211 - val_accuracy: 0.4725\n",
            "Epoch 223/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0144 - accuracy: 0.6523 - val_loss: 0.0211 - val_accuracy: 0.4666\n",
            "Epoch 224/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0143 - accuracy: 0.6563 - val_loss: 0.0209 - val_accuracy: 0.4695\n",
            "Epoch 225/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0142 - accuracy: 0.6555 - val_loss: 0.0216 - val_accuracy: 0.4607\n",
            "Epoch 226/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0144 - accuracy: 0.6494 - val_loss: 0.0210 - val_accuracy: 0.4695\n",
            "Epoch 227/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0140 - accuracy: 0.6585 - val_loss: 0.0209 - val_accuracy: 0.4760\n",
            "Epoch 228/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0139 - accuracy: 0.6586 - val_loss: 0.0218 - val_accuracy: 0.4447\n",
            "Epoch 229/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0139 - accuracy: 0.6616 - val_loss: 0.0213 - val_accuracy: 0.4672\n",
            "Epoch 230/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0140 - accuracy: 0.6596 - val_loss: 0.0209 - val_accuracy: 0.4796\n",
            "Epoch 231/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0139 - accuracy: 0.6630 - val_loss: 0.0219 - val_accuracy: 0.4441\n",
            "Epoch 232/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0140 - accuracy: 0.6618 - val_loss: 0.0214 - val_accuracy: 0.4624\n",
            "Epoch 233/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0137 - accuracy: 0.6717 - val_loss: 0.0211 - val_accuracy: 0.4660\n",
            "Epoch 234/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0138 - accuracy: 0.6665 - val_loss: 0.0210 - val_accuracy: 0.4690\n",
            "Epoch 235/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0137 - accuracy: 0.6661 - val_loss: 0.0213 - val_accuracy: 0.4607\n",
            "Epoch 236/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0143 - accuracy: 0.6521 - val_loss: 0.0218 - val_accuracy: 0.4548\n",
            "Epoch 237/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0137 - accuracy: 0.6705 - val_loss: 0.0210 - val_accuracy: 0.4684\n",
            "Epoch 238/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0138 - accuracy: 0.6661 - val_loss: 0.0214 - val_accuracy: 0.4548\n",
            "Epoch 239/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0136 - accuracy: 0.6728 - val_loss: 0.0214 - val_accuracy: 0.4607\n",
            "Epoch 240/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0135 - accuracy: 0.6719 - val_loss: 0.0212 - val_accuracy: 0.4684\n",
            "Epoch 241/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0140 - accuracy: 0.6579 - val_loss: 0.0213 - val_accuracy: 0.4684\n",
            "Epoch 242/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0137 - accuracy: 0.6695 - val_loss: 0.0217 - val_accuracy: 0.4471\n",
            "Epoch 243/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0134 - accuracy: 0.6768 - val_loss: 0.0218 - val_accuracy: 0.4577\n",
            "Epoch 244/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0136 - accuracy: 0.6756 - val_loss: 0.0209 - val_accuracy: 0.4749\n",
            "Epoch 245/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0136 - accuracy: 0.6748 - val_loss: 0.0212 - val_accuracy: 0.4630\n",
            "Epoch 246/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0134 - accuracy: 0.6797 - val_loss: 0.0212 - val_accuracy: 0.4607\n",
            "Epoch 247/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0132 - accuracy: 0.6831 - val_loss: 0.0209 - val_accuracy: 0.4814\n",
            "Epoch 248/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0133 - accuracy: 0.6782 - val_loss: 0.0211 - val_accuracy: 0.4749\n",
            "Epoch 249/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0134 - accuracy: 0.6784 - val_loss: 0.0216 - val_accuracy: 0.4684\n",
            "Epoch 250/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0131 - accuracy: 0.6861 - val_loss: 0.0212 - val_accuracy: 0.4725\n",
            "Epoch 251/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0131 - accuracy: 0.6868 - val_loss: 0.0211 - val_accuracy: 0.4755\n",
            "Epoch 252/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0131 - accuracy: 0.6849 - val_loss: 0.0214 - val_accuracy: 0.4642\n",
            "Epoch 253/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0131 - accuracy: 0.6866 - val_loss: 0.0212 - val_accuracy: 0.4713\n",
            "Epoch 254/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0133 - accuracy: 0.6788 - val_loss: 0.0213 - val_accuracy: 0.4713\n",
            "Epoch 255/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0129 - accuracy: 0.6945 - val_loss: 0.0211 - val_accuracy: 0.4719\n",
            "Epoch 256/500\n",
            "159/159 [==============================] - 6s 38ms/step - loss: 0.0132 - accuracy: 0.6803 - val_loss: 0.0212 - val_accuracy: 0.4772\n",
            "Epoch 257/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0131 - accuracy: 0.6861 - val_loss: 0.0218 - val_accuracy: 0.4512\n",
            "Epoch 258/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0132 - accuracy: 0.6815 - val_loss: 0.0214 - val_accuracy: 0.4725\n",
            "Epoch 259/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0130 - accuracy: 0.6884 - val_loss: 0.0218 - val_accuracy: 0.4624\n",
            "Epoch 260/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0128 - accuracy: 0.6882 - val_loss: 0.0217 - val_accuracy: 0.4607\n",
            "Epoch 261/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0128 - accuracy: 0.6991 - val_loss: 0.0212 - val_accuracy: 0.4713\n",
            "Epoch 262/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0131 - accuracy: 0.6863 - val_loss: 0.0210 - val_accuracy: 0.4820\n",
            "Epoch 263/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0125 - accuracy: 0.6987 - val_loss: 0.0215 - val_accuracy: 0.4642\n",
            "Epoch 264/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0128 - accuracy: 0.6930 - val_loss: 0.0214 - val_accuracy: 0.4654\n",
            "Epoch 265/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0129 - accuracy: 0.6904 - val_loss: 0.0212 - val_accuracy: 0.4695\n",
            "Epoch 266/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0128 - accuracy: 0.6902 - val_loss: 0.0215 - val_accuracy: 0.4648\n",
            "Epoch 267/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0125 - accuracy: 0.7012 - val_loss: 0.0214 - val_accuracy: 0.4826\n",
            "Epoch 268/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0125 - accuracy: 0.7010 - val_loss: 0.0213 - val_accuracy: 0.4772\n",
            "Epoch 269/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0126 - accuracy: 0.7012 - val_loss: 0.0219 - val_accuracy: 0.4678\n",
            "Epoch 270/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0128 - accuracy: 0.6967 - val_loss: 0.0212 - val_accuracy: 0.4790\n",
            "Epoch 271/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0126 - accuracy: 0.6999 - val_loss: 0.0214 - val_accuracy: 0.4666\n",
            "Epoch 272/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0123 - accuracy: 0.7048 - val_loss: 0.0216 - val_accuracy: 0.4731\n",
            "Epoch 273/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0123 - accuracy: 0.7107 - val_loss: 0.0211 - val_accuracy: 0.4760\n",
            "Epoch 274/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0122 - accuracy: 0.7081 - val_loss: 0.0218 - val_accuracy: 0.4725\n",
            "Epoch 275/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0126 - accuracy: 0.6934 - val_loss: 0.0210 - val_accuracy: 0.4778\n",
            "Epoch 276/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0123 - accuracy: 0.7060 - val_loss: 0.0215 - val_accuracy: 0.4666\n",
            "Epoch 277/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0122 - accuracy: 0.7121 - val_loss: 0.0218 - val_accuracy: 0.4571\n",
            "Epoch 278/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0121 - accuracy: 0.7097 - val_loss: 0.0216 - val_accuracy: 0.4678\n",
            "Epoch 279/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0121 - accuracy: 0.7107 - val_loss: 0.0227 - val_accuracy: 0.4500\n",
            "Epoch 280/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0125 - accuracy: 0.7003 - val_loss: 0.0219 - val_accuracy: 0.4654\n",
            "Epoch 281/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0120 - accuracy: 0.7214 - val_loss: 0.0211 - val_accuracy: 0.4831\n",
            "Epoch 282/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0122 - accuracy: 0.7113 - val_loss: 0.0216 - val_accuracy: 0.4660\n",
            "Epoch 283/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0121 - accuracy: 0.7121 - val_loss: 0.0219 - val_accuracy: 0.4595\n",
            "Epoch 284/500\n",
            "159/159 [==============================] - 6s 35ms/step - loss: 0.0120 - accuracy: 0.7123 - val_loss: 0.0215 - val_accuracy: 0.4701\n",
            "Epoch 285/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0120 - accuracy: 0.7143 - val_loss: 0.0216 - val_accuracy: 0.4672\n",
            "Epoch 286/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0119 - accuracy: 0.7182 - val_loss: 0.0212 - val_accuracy: 0.4826\n",
            "Epoch 287/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0121 - accuracy: 0.7131 - val_loss: 0.0216 - val_accuracy: 0.4701\n",
            "Epoch 288/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0119 - accuracy: 0.7174 - val_loss: 0.0212 - val_accuracy: 0.4772\n",
            "Epoch 289/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0121 - accuracy: 0.7147 - val_loss: 0.0220 - val_accuracy: 0.4500\n",
            "Epoch 290/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0117 - accuracy: 0.7219 - val_loss: 0.0210 - val_accuracy: 0.4849\n",
            "Epoch 291/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0123 - accuracy: 0.7087 - val_loss: 0.0216 - val_accuracy: 0.4636\n",
            "Epoch 292/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0116 - accuracy: 0.7233 - val_loss: 0.0216 - val_accuracy: 0.4672\n",
            "Epoch 293/500\n",
            "159/159 [==============================] - 6s 37ms/step - loss: 0.0117 - accuracy: 0.7251 - val_loss: 0.0215 - val_accuracy: 0.4784\n",
            "Epoch 294/500\n",
            "159/159 [==============================] - 6s 35ms/step - loss: 0.0121 - accuracy: 0.7123 - val_loss: 0.0216 - val_accuracy: 0.4701\n",
            "Epoch 295/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0119 - accuracy: 0.7168 - val_loss: 0.0220 - val_accuracy: 0.4589\n",
            "Epoch 296/500\n",
            "159/159 [==============================] - 6s 35ms/step - loss: 0.0116 - accuracy: 0.7249 - val_loss: 0.0224 - val_accuracy: 0.4613\n",
            "Epoch 297/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0117 - accuracy: 0.7206 - val_loss: 0.0232 - val_accuracy: 0.4270\n",
            "Epoch 298/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0118 - accuracy: 0.7210 - val_loss: 0.0214 - val_accuracy: 0.4755\n",
            "Epoch 299/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0117 - accuracy: 0.7216 - val_loss: 0.0212 - val_accuracy: 0.4749\n",
            "Epoch 300/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0113 - accuracy: 0.7318 - val_loss: 0.0215 - val_accuracy: 0.4731\n",
            "Epoch 301/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0115 - accuracy: 0.7298 - val_loss: 0.0225 - val_accuracy: 0.4554\n",
            "Epoch 302/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0117 - accuracy: 0.7212 - val_loss: 0.0216 - val_accuracy: 0.4725\n",
            "Epoch 303/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0113 - accuracy: 0.7375 - val_loss: 0.0212 - val_accuracy: 0.4837\n",
            "Epoch 304/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0116 - accuracy: 0.7233 - val_loss: 0.0221 - val_accuracy: 0.4607\n",
            "Epoch 305/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0113 - accuracy: 0.7340 - val_loss: 0.0218 - val_accuracy: 0.4619\n",
            "Epoch 306/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0114 - accuracy: 0.7354 - val_loss: 0.0220 - val_accuracy: 0.4701\n",
            "Epoch 307/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0116 - accuracy: 0.7265 - val_loss: 0.0214 - val_accuracy: 0.4755\n",
            "Epoch 308/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0115 - accuracy: 0.7259 - val_loss: 0.0223 - val_accuracy: 0.4565\n",
            "Epoch 309/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0113 - accuracy: 0.7324 - val_loss: 0.0220 - val_accuracy: 0.4660\n",
            "Epoch 310/500\n",
            "159/159 [==============================] - 5s 32ms/step - loss: 0.0113 - accuracy: 0.7340 - val_loss: 0.0224 - val_accuracy: 0.4559\n",
            "Epoch 311/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0115 - accuracy: 0.7324 - val_loss: 0.0222 - val_accuracy: 0.4589\n",
            "Epoch 312/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0116 - accuracy: 0.7279 - val_loss: 0.0216 - val_accuracy: 0.4772\n",
            "Epoch 313/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0111 - accuracy: 0.7342 - val_loss: 0.0218 - val_accuracy: 0.4701\n",
            "Epoch 314/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0111 - accuracy: 0.7417 - val_loss: 0.0214 - val_accuracy: 0.4849\n",
            "Epoch 315/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0109 - accuracy: 0.7421 - val_loss: 0.0221 - val_accuracy: 0.4701\n",
            "Epoch 316/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0109 - accuracy: 0.7474 - val_loss: 0.0219 - val_accuracy: 0.4619\n",
            "Epoch 317/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0111 - accuracy: 0.7371 - val_loss: 0.0216 - val_accuracy: 0.4802\n",
            "Epoch 318/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0109 - accuracy: 0.7436 - val_loss: 0.0219 - val_accuracy: 0.4755\n",
            "Epoch 319/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0108 - accuracy: 0.7442 - val_loss: 0.0218 - val_accuracy: 0.4772\n",
            "Epoch 320/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0110 - accuracy: 0.7460 - val_loss: 0.0219 - val_accuracy: 0.4719\n",
            "Epoch 321/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0109 - accuracy: 0.7440 - val_loss: 0.0212 - val_accuracy: 0.4820\n",
            "Epoch 322/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0110 - accuracy: 0.7409 - val_loss: 0.0218 - val_accuracy: 0.4778\n",
            "Epoch 323/500\n",
            "159/159 [==============================] - 5s 34ms/step - loss: 0.0109 - accuracy: 0.7434 - val_loss: 0.0213 - val_accuracy: 0.4814\n",
            "Epoch 324/500\n",
            "159/159 [==============================] - 5s 33ms/step - loss: 0.0108 - accuracy: 0.7454 - val_loss: 0.0216 - val_accuracy: 0.4684\n",
            "Epoch 325/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0106 - accuracy: 0.7547 - val_loss: 0.0217 - val_accuracy: 0.4796\n",
            "Epoch 326/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0108 - accuracy: 0.7486 - val_loss: 0.0222 - val_accuracy: 0.4725\n",
            "Epoch 327/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0107 - accuracy: 0.7505 - val_loss: 0.0215 - val_accuracy: 0.4802\n",
            "Epoch 328/500\n",
            "159/159 [==============================] - 10s 63ms/step - loss: 0.0108 - accuracy: 0.7446 - val_loss: 0.0222 - val_accuracy: 0.4548\n",
            "Epoch 329/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0109 - accuracy: 0.7466 - val_loss: 0.0215 - val_accuracy: 0.4820\n",
            "Epoch 330/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0105 - accuracy: 0.7551 - val_loss: 0.0216 - val_accuracy: 0.4784\n",
            "Epoch 331/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0107 - accuracy: 0.7474 - val_loss: 0.0215 - val_accuracy: 0.4867\n",
            "Epoch 332/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0107 - accuracy: 0.7523 - val_loss: 0.0216 - val_accuracy: 0.4725\n",
            "Epoch 333/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0105 - accuracy: 0.7565 - val_loss: 0.0216 - val_accuracy: 0.4766\n",
            "Epoch 334/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0112 - accuracy: 0.7358 - val_loss: 0.0228 - val_accuracy: 0.4536\n",
            "Epoch 335/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0107 - accuracy: 0.7456 - val_loss: 0.0217 - val_accuracy: 0.4879\n",
            "Epoch 336/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0103 - accuracy: 0.7600 - val_loss: 0.0216 - val_accuracy: 0.4778\n",
            "Epoch 337/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0109 - accuracy: 0.7421 - val_loss: 0.0214 - val_accuracy: 0.4831\n",
            "Epoch 338/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0104 - accuracy: 0.7582 - val_loss: 0.0218 - val_accuracy: 0.4831\n",
            "Epoch 339/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0102 - accuracy: 0.7624 - val_loss: 0.0230 - val_accuracy: 0.4542\n",
            "Epoch 340/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0106 - accuracy: 0.7505 - val_loss: 0.0218 - val_accuracy: 0.4737\n",
            "Epoch 341/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0106 - accuracy: 0.7537 - val_loss: 0.0216 - val_accuracy: 0.4855\n",
            "Epoch 342/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0103 - accuracy: 0.7608 - val_loss: 0.0215 - val_accuracy: 0.4796\n",
            "Epoch 343/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0102 - accuracy: 0.7663 - val_loss: 0.0218 - val_accuracy: 0.4701\n",
            "Epoch 344/500\n",
            "159/159 [==============================] - 8s 51ms/step - loss: 0.0103 - accuracy: 0.7590 - val_loss: 0.0217 - val_accuracy: 0.4849\n",
            "Epoch 345/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0102 - accuracy: 0.7614 - val_loss: 0.0216 - val_accuracy: 0.4802\n",
            "Epoch 346/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0101 - accuracy: 0.7679 - val_loss: 0.0213 - val_accuracy: 0.4831\n",
            "Epoch 347/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0101 - accuracy: 0.7616 - val_loss: 0.0220 - val_accuracy: 0.4695\n",
            "Epoch 348/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0100 - accuracy: 0.7651 - val_loss: 0.0218 - val_accuracy: 0.4760\n",
            "Epoch 349/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0103 - accuracy: 0.7610 - val_loss: 0.0221 - val_accuracy: 0.4660\n",
            "Epoch 350/500\n",
            "159/159 [==============================] - 9s 60ms/step - loss: 0.0104 - accuracy: 0.7545 - val_loss: 0.0231 - val_accuracy: 0.4394\n",
            "Epoch 351/500\n",
            "159/159 [==============================] - 10s 63ms/step - loss: 0.0103 - accuracy: 0.7614 - val_loss: 0.0234 - val_accuracy: 0.4347\n",
            "Epoch 352/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0101 - accuracy: 0.7677 - val_loss: 0.0219 - val_accuracy: 0.4695\n",
            "Epoch 353/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0098 - accuracy: 0.7758 - val_loss: 0.0221 - val_accuracy: 0.4690\n",
            "Epoch 354/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0099 - accuracy: 0.7722 - val_loss: 0.0217 - val_accuracy: 0.4743\n",
            "Epoch 355/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0097 - accuracy: 0.7756 - val_loss: 0.0224 - val_accuracy: 0.4654\n",
            "Epoch 356/500\n",
            "159/159 [==============================] - 9s 60ms/step - loss: 0.0098 - accuracy: 0.7732 - val_loss: 0.0222 - val_accuracy: 0.4719\n",
            "Epoch 357/500\n",
            "159/159 [==============================] - 9s 53ms/step - loss: 0.0098 - accuracy: 0.7716 - val_loss: 0.0218 - val_accuracy: 0.4802\n",
            "Epoch 358/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0100 - accuracy: 0.7691 - val_loss: 0.0227 - val_accuracy: 0.4577\n",
            "Epoch 359/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0097 - accuracy: 0.7752 - val_loss: 0.0213 - val_accuracy: 0.4820\n",
            "Epoch 360/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0096 - accuracy: 0.7756 - val_loss: 0.0218 - val_accuracy: 0.4826\n",
            "Epoch 361/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0100 - accuracy: 0.7685 - val_loss: 0.0221 - val_accuracy: 0.4731\n",
            "Epoch 362/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0098 - accuracy: 0.7707 - val_loss: 0.0225 - val_accuracy: 0.4707\n",
            "Epoch 363/500\n",
            "159/159 [==============================] - 8s 52ms/step - loss: 0.0097 - accuracy: 0.7758 - val_loss: 0.0223 - val_accuracy: 0.4713\n",
            "Epoch 364/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0097 - accuracy: 0.7742 - val_loss: 0.0216 - val_accuracy: 0.4873\n",
            "Epoch 365/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0098 - accuracy: 0.7776 - val_loss: 0.0215 - val_accuracy: 0.4902\n",
            "Epoch 366/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0097 - accuracy: 0.7752 - val_loss: 0.0226 - val_accuracy: 0.4678\n",
            "Epoch 367/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0098 - accuracy: 0.7711 - val_loss: 0.0224 - val_accuracy: 0.4737\n",
            "Epoch 368/500\n",
            "159/159 [==============================] - 9s 60ms/step - loss: 0.0095 - accuracy: 0.7815 - val_loss: 0.0215 - val_accuracy: 0.4814\n",
            "Epoch 369/500\n",
            "159/159 [==============================] - 10s 60ms/step - loss: 0.0098 - accuracy: 0.7718 - val_loss: 0.0220 - val_accuracy: 0.4796\n",
            "Epoch 370/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0099 - accuracy: 0.7691 - val_loss: 0.0224 - val_accuracy: 0.4672\n",
            "Epoch 371/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0096 - accuracy: 0.7750 - val_loss: 0.0217 - val_accuracy: 0.4814\n",
            "Epoch 372/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0096 - accuracy: 0.7821 - val_loss: 0.0224 - val_accuracy: 0.4719\n",
            "Epoch 373/500\n",
            "159/159 [==============================] - 8s 53ms/step - loss: 0.0095 - accuracy: 0.7783 - val_loss: 0.0219 - val_accuracy: 0.4760\n",
            "Epoch 374/500\n",
            "159/159 [==============================] - 15s 93ms/step - loss: 0.0094 - accuracy: 0.7823 - val_loss: 0.0233 - val_accuracy: 0.4583\n",
            "Epoch 375/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0099 - accuracy: 0.7711 - val_loss: 0.0219 - val_accuracy: 0.4737\n",
            "Epoch 376/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0098 - accuracy: 0.7758 - val_loss: 0.0220 - val_accuracy: 0.4684\n",
            "Epoch 377/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0093 - accuracy: 0.7858 - val_loss: 0.0220 - val_accuracy: 0.4707\n",
            "Epoch 378/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0093 - accuracy: 0.7825 - val_loss: 0.0218 - val_accuracy: 0.4790\n",
            "Epoch 379/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0093 - accuracy: 0.7876 - val_loss: 0.0217 - val_accuracy: 0.4831\n",
            "Epoch 380/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0093 - accuracy: 0.7878 - val_loss: 0.0218 - val_accuracy: 0.4796\n",
            "Epoch 381/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0095 - accuracy: 0.7783 - val_loss: 0.0223 - val_accuracy: 0.4731\n",
            "Epoch 382/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0092 - accuracy: 0.7900 - val_loss: 0.0244 - val_accuracy: 0.4199\n",
            "Epoch 383/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0091 - accuracy: 0.7904 - val_loss: 0.0234 - val_accuracy: 0.4548\n",
            "Epoch 384/500\n",
            "159/159 [==============================] - 9s 60ms/step - loss: 0.0095 - accuracy: 0.7803 - val_loss: 0.0218 - val_accuracy: 0.4760\n",
            "Epoch 385/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0090 - accuracy: 0.7933 - val_loss: 0.0220 - val_accuracy: 0.4820\n",
            "Epoch 386/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0095 - accuracy: 0.7795 - val_loss: 0.0224 - val_accuracy: 0.4743\n",
            "Epoch 387/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0090 - accuracy: 0.7902 - val_loss: 0.0222 - val_accuracy: 0.4678\n",
            "Epoch 388/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0095 - accuracy: 0.7803 - val_loss: 0.0223 - val_accuracy: 0.4778\n",
            "Epoch 389/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0090 - accuracy: 0.7927 - val_loss: 0.0226 - val_accuracy: 0.4678\n",
            "Epoch 390/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0092 - accuracy: 0.7882 - val_loss: 0.0219 - val_accuracy: 0.4808\n",
            "Epoch 391/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0091 - accuracy: 0.7920 - val_loss: 0.0217 - val_accuracy: 0.4837\n",
            "Epoch 392/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0090 - accuracy: 0.7923 - val_loss: 0.0231 - val_accuracy: 0.4447\n",
            "Epoch 393/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0093 - accuracy: 0.7858 - val_loss: 0.0224 - val_accuracy: 0.4695\n",
            "Epoch 394/500\n",
            "159/159 [==============================] - 10s 66ms/step - loss: 0.0090 - accuracy: 0.7927 - val_loss: 0.0225 - val_accuracy: 0.4684\n",
            "Epoch 395/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0090 - accuracy: 0.7933 - val_loss: 0.0219 - val_accuracy: 0.4796\n",
            "Epoch 396/500\n",
            "159/159 [==============================] - 10s 65ms/step - loss: 0.0092 - accuracy: 0.7868 - val_loss: 0.0224 - val_accuracy: 0.4731\n",
            "Epoch 397/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0091 - accuracy: 0.7922 - val_loss: 0.0220 - val_accuracy: 0.4802\n",
            "Epoch 398/500\n",
            "159/159 [==============================] - 9s 54ms/step - loss: 0.0089 - accuracy: 0.7969 - val_loss: 0.0222 - val_accuracy: 0.4690\n",
            "Epoch 399/500\n",
            "159/159 [==============================] - 13s 80ms/step - loss: 0.0096 - accuracy: 0.7809 - val_loss: 0.0231 - val_accuracy: 0.4595\n",
            "Epoch 400/500\n",
            "159/159 [==============================] - 13s 83ms/step - loss: 0.0091 - accuracy: 0.7888 - val_loss: 0.0222 - val_accuracy: 0.4731\n",
            "Epoch 401/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0088 - accuracy: 0.7998 - val_loss: 0.0220 - val_accuracy: 0.4772\n",
            "Epoch 402/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0088 - accuracy: 0.7983 - val_loss: 0.0222 - val_accuracy: 0.4802\n",
            "Epoch 403/500\n",
            "159/159 [==============================] - 9s 60ms/step - loss: 0.0085 - accuracy: 0.8022 - val_loss: 0.0221 - val_accuracy: 0.4855\n",
            "Epoch 404/500\n",
            "159/159 [==============================] - 9s 55ms/step - loss: 0.0087 - accuracy: 0.8024 - val_loss: 0.0218 - val_accuracy: 0.4837\n",
            "Epoch 405/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0088 - accuracy: 0.8010 - val_loss: 0.0220 - val_accuracy: 0.4837\n",
            "Epoch 406/500\n",
            "159/159 [==============================] - 11s 68ms/step - loss: 0.0090 - accuracy: 0.7914 - val_loss: 0.0235 - val_accuracy: 0.4471\n",
            "Epoch 407/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0091 - accuracy: 0.7880 - val_loss: 0.0223 - val_accuracy: 0.4778\n",
            "Epoch 408/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0087 - accuracy: 0.8004 - val_loss: 0.0220 - val_accuracy: 0.4837\n",
            "Epoch 409/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0088 - accuracy: 0.7993 - val_loss: 0.0228 - val_accuracy: 0.4684\n",
            "Epoch 410/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0088 - accuracy: 0.7961 - val_loss: 0.0226 - val_accuracy: 0.4613\n",
            "Epoch 411/500\n",
            "159/159 [==============================] - 18s 115ms/step - loss: 0.0084 - accuracy: 0.8103 - val_loss: 0.0223 - val_accuracy: 0.4743\n",
            "Epoch 412/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0087 - accuracy: 0.8006 - val_loss: 0.0223 - val_accuracy: 0.4760\n",
            "Epoch 413/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0086 - accuracy: 0.8010 - val_loss: 0.0230 - val_accuracy: 0.4583\n",
            "Epoch 414/500\n",
            "159/159 [==============================] - 18s 116ms/step - loss: 0.0089 - accuracy: 0.7939 - val_loss: 0.0223 - val_accuracy: 0.4707\n",
            "Epoch 415/500\n",
            "159/159 [==============================] - 15s 92ms/step - loss: 0.0086 - accuracy: 0.8022 - val_loss: 0.0227 - val_accuracy: 0.4707\n",
            "Epoch 416/500\n",
            "159/159 [==============================] - 19s 118ms/step - loss: 0.0090 - accuracy: 0.7916 - val_loss: 0.0221 - val_accuracy: 0.4772\n",
            "Epoch 417/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0082 - accuracy: 0.8129 - val_loss: 0.0221 - val_accuracy: 0.4891\n",
            "Epoch 418/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0083 - accuracy: 0.8105 - val_loss: 0.0219 - val_accuracy: 0.4831\n",
            "Epoch 419/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0086 - accuracy: 0.8040 - val_loss: 0.0220 - val_accuracy: 0.4772\n",
            "Epoch 420/500\n",
            "159/159 [==============================] - 9s 56ms/step - loss: 0.0081 - accuracy: 0.8156 - val_loss: 0.0218 - val_accuracy: 0.4867\n",
            "Epoch 421/500\n",
            "159/159 [==============================] - 18s 116ms/step - loss: 0.0083 - accuracy: 0.8085 - val_loss: 0.0229 - val_accuracy: 0.4624\n",
            "Epoch 422/500\n",
            "159/159 [==============================] - 9s 57ms/step - loss: 0.0089 - accuracy: 0.7955 - val_loss: 0.0224 - val_accuracy: 0.4707\n",
            "Epoch 423/500\n",
            "159/159 [==============================] - 18s 116ms/step - loss: 0.0082 - accuracy: 0.8140 - val_loss: 0.0221 - val_accuracy: 0.4873\n",
            "Epoch 424/500\n",
            "159/159 [==============================] - 19s 117ms/step - loss: 0.0084 - accuracy: 0.8069 - val_loss: 0.0222 - val_accuracy: 0.4784\n",
            "Epoch 425/500\n",
            "159/159 [==============================] - 19s 117ms/step - loss: 0.0084 - accuracy: 0.8109 - val_loss: 0.0228 - val_accuracy: 0.4690\n",
            "Epoch 426/500\n",
            "159/159 [==============================] - 9s 59ms/step - loss: 0.0084 - accuracy: 0.8085 - val_loss: 0.0224 - val_accuracy: 0.4678\n",
            "Epoch 427/500\n",
            "159/159 [==============================] - 19s 118ms/step - loss: 0.0082 - accuracy: 0.8107 - val_loss: 0.0221 - val_accuracy: 0.4820\n",
            "Epoch 428/500\n",
            "159/159 [==============================] - 19s 118ms/step - loss: 0.0082 - accuracy: 0.8119 - val_loss: 0.0228 - val_accuracy: 0.4760\n",
            "Epoch 429/500\n",
            "159/159 [==============================] - 9s 57ms/step - loss: 0.0081 - accuracy: 0.8156 - val_loss: 0.0226 - val_accuracy: 0.4713\n",
            "Epoch 430/500\n",
            "159/159 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.8073"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = model3.evaluate(X_test,Y_test)\n",
        "print('\\n테스트 정확도:', test_acc*100)"
      ],
      "metadata": {
        "id": "TEnrcueayf-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'], linewidth=\"2\")\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy Trend')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','test'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "el1L9SBxydr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모델비교"
      ],
      "metadata": {
        "id": "cRPpaQbPIqGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![model0.png](data:image/png;base64,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)![model1.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmAAAAGCCAYAAABHD3/EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVd7/8fdJMumVhCRA6FVAugrYggXLuuray6q7FrY8un2fdffZ3tyf67p93dUt7ip2V1dREVEDsoAKCNJ7C5BCEtLrzPn9cSYh9ARmMjPJ53VduabcM/d8czNkPnPOuc8x1lpEREREpOtEhboAERERkZ5GAUxERESkiymAiYiIiHQxBTARERGRLqYAJiIiItLFFMBEREREupgCmIhIBDDG7DDGTA11HSISGDGhLkBEujdjTBrwEbDaWntVqOs5FcaY54H+/pujgWKgzH/7IWvtCyEpTEQijgKYiATbzcCjwG3GmD7W2n2hLuhkWWuvb71ujCkA/mytfSZ0FYlIpFIXpIgE213Av4EXgTvabzDG3G6M+cAY874x5r/GmEuNMVHGmK8ZY1YYY5YaYxYYYyYbYwqMMTe1e+5N/hCEMeaHxpjXjTGvGWM+Nsacboy5wxizxL+PtcaY29o9d6ox5m1jzIf+x3zLGLPaGHNVu8eMM8ZsM8aYjv6ixpjHjTFP+mtdb4xJ8+9nrjFmkf93+j//Y/ONMbuMMT/x17DeGPO1dvu62xizwRjznjHmT0Bsp4+8iIQttYCJSNAYY8YB8dbaTcaYZ4GXgF/4t10DfA+YYa0tNMbEAoOBrwDXARdaayuMMclAVgdebgow0Vq7x7//POBia22NMWYUsBB4whgzEJgDfMpa+57/sacD5cAs4D/+/d0GPGY7v17bJGCatbbSGJMCPANcY63dYIzxAIuMMcuARlx35l5r7TRjTC6wzRjzT+A04PvAFGttiTHmUuALnaxDRMKYApiIBNNduJYvrLVrjTFNxpjzrbULgBuA31trC/3bm4CN/gDyc2tthf/+GqCmAw1Rc1vDl98O4P+MMSOAOKC3//7LgIWt4cv/GquNMVuAnxljBgCFuBA47SR+5xestZX+62cDfYHH29WfBgwH1gCl1tpH/DUUGWPKgEHAVcBz1toS/7a5xpiI7boVkSMpgIlIUBhj4oBbgVJjzNX+u3sBdwMLcEMgfEd56rHubwGi291OOWx7XbvXHgLMB24Cvut/XuPx9m+trTfG/NVf30JgubW26Di/4rHUtbseBWy21h5x9qIxJh/X6taeF/AA8UDVYduiEZFuQ2PARCRYrgbWW2tPs9ZOsNZOACYAV/rPjHwV+LwxJhtcYDPGjPHf/1V/9x3GmFRjzDBgI3CG/74UXFA6lvFAKbDIWusFvtxu23xghjFmSusdxphJ/qt/BG73/zx6ar8+AIuB/v4uxNbXmmCMyTzB894DrjHGpPqfczWQHYB6RCRMqAVMRILlLuCx9nf4xzO9Ddxqrf2TP0jNNca0AM24cU8/BwzwnjGmEWgAvgQ8AMz2j5+qAZbgAt3RzMOFqC3GmGIOjuvCPx7teuDXxph4XGvYM8AKa+0eY8wSYCqHnTBwMqy1B4wxVwAPGmN+6n+tvcCdJ3jq88BEYIkxphJYz5GtZSISwUznx5eKiHRfxpgfAE3W2gdCXYuIdF8KYCIifsaYdGApMN1aqxYnEQkajQETEQGMMb/Djb36hsKXiASbWsBEREREuphawERERES6mAKYiIiISBeLqGkosrKy7KBBg4L6GrW1tSQlJQX1NcKdjoGOAegYgI4B6Bi00nHQMYDOH4Ply5fvt9b2Ptq2iApggwYNYtmyZUF9jYKCAvLz84P6GuFOx0DHAHQMQMcAdAxa6TjoGEDnj4ExZuextqkLUkRERKSLKYCJiIiIdDEFMBEREZEuFlFjwI6mubmZwsJCGhoaArK/tLQ01q9fH5B9BUJ8fDx5eXl4PJ5QlyIiIiIBEvEBrLCwkJSUFAYNGoQx5pT3V11dTUpKSgAqO3XWWsrKyigsLGTw4MGhLkdEREQCJOK7IBsaGsjMzAxI+Ao3xhgyMzMD1ronIiIi4SHiAxjQLcNXq+78u4mIiPRU3SKAhdpDDz3U4ccWFhbyla98JYjViIiISLgLWgAzxow0xiw2xjxzjO0/829fYozJD1YdXaEzASwvL4/f/OY3QaxGREREwl0wB+GfBfwOuPrwDcaYC4AJ1trpxpi+wDvGmLHW2pZTecFB9792Kk8/ph2/+MQxt1122WWUl5eTn5+PMYb+/fuzd+9ebr75ZrxeL7Nnz8bn85GWlsZLL73Enj17uOmmm1i6dCmf+cxnSEpKYtOmTRQVFfHtb3+bW265JSi/g4iIiISPoLWAWWv/BRQdY/OFwPP+x+0FdgIjg1VLML3xxhv06tWLgoICBg4cSFZWFvPnz+euu+7inHPOoaCggBdffJGKigo++uijI55fV1fHvHnzeP3113nggQdC8BuIiIhIVwvVNBS9gSXtbu/333cEY8wsYBZATk4OBQUFh2xPS0ujuroagNX/d94pF+b1eomOjj7kvtb9H4u1lurqapqbm5k+fTrV1dVYa3nkkUdoaGhgyJAh+Hw+9u/fT2JiIl6vt+3xV111FTU1NaSnp1NaWnrU12poaDji9w6mmpqaLn29cKRjoGMAOgagY9Cqpx6H2mbLpgovOyp9eGwTK0vm0zsxiqwEQ1x0zztJLJDvg1AFsFogrd3tNKDiaA+01j4KPAowZcoUe/gimOvXrw/ovF0nMw+YMYaUlBQ8Hg/JycmkpKTw0UcfsXHjRubNm0dtbS1PPPEEiYmJJCcnEx0d3fb41NTUQ17vaK8dHx/PxIkTT/l36ygtuKpjADoGoGMAxz4G1lqqG1sorW6ktLqRkrbLBg7UNhMTbYj3RBPviSI+JrrtepzHfz0myn+fuz8xNob+vRKIi4k+sogw0FPeC5X1zXy4vZyl28pYur2MtXursLZ1qwEa2x7bOyWO/hkJDOiVSP/Wn4xE+vdKoE9aAtFRgQ9oTS0+ymobKak6+L6rqGsiPdFDbmo8Oanx5KbF0ysxlqggvH4g3wddFsCMMdFAkrW2CngbuA2YbYzJwnU/buyqWgJtwoQJXH755cybN4+bbroJgBEjRtDS0sIZZ5xBXl4eOTk5Ia5SRKRjGlu87DvQQGFFPQsKm1n99ua2gFVa40JWaXUjDc2+gL5uTJRhcFYSI3NTGJWbwsjcVEbmpJCXkRCUD9Nw1+L1sb+mieKqBkqqG91l++vVjVTUNpGVEkdeRgJ5GYn+y4PXE2OP/zFf1dAucG0rZ+3eSnz24HZPtGFi/wwmDkhn4/ZdeOPT2V1eR2FFfVv4XrHrwBH79UQb+qQlkJoQQ2JsDImx0STFxpAQG01SbDQJsTEkxUaTGOe2uZ8Y4mKiqKhratv34eG+oq65Q8fOE23ITnFhLCc1zgWz1NbbB6/He0IX+LuyBewm4EbgSuA1YKYxZjFuHNqXrbURO9vo3Llzj7gvKSmJd95556iPX7p0KQCPP/74IfcXFR1ryJxI+PL6LDvLatlYVE1JdSNnD8tkWHZwV5Oob/IS74kK+jx51toTP6gLWGspqmpgS0lN28+eA/UkxcXQKzGWjEQP6YmxZCS5S3dfLOlJHlLiYo44Tu0DVmFF3WGX9RRXN3DIr75m01HrSvBEk50aR3ZKHL1T4shOiad3ShwZibF4fT4amn00NHtpaPEevN7so6HFS2Oz95DtVfUt7K6oY3NJDZtLapjz8b6210mKjWZ4TmsoS/EHtFR6JcViraW2yUtFbRNltU3Hvqxrory2icr6ZgwQHWWIiTJERxtioqKIMhATFeXujzZt26OMu32gop6/bnm/U/9uxkCUcfuK8l9vu+2/L9oYjDFER4HPQllNoz9gNVJW20hH3oJ7Kxv4uLDyqNsyk2KPCGfpibF8XHjgmIFrcv90pg7JZOqQTCYNyCAh1oWUgoJi8vPPAtz/+6KqBnaV1bG7oo7C8jp2ldexu6KeXeV1lFY3squ8rlPHqyOiDGQmH3zP9U6OIyMplgN1TRRVNVJc2UBRVQOV9c3sOVDPngP1x9zXNRP78fCNEwJeY0cFNYBZawuAAv/12cBs/3ULfCmYry0igWWtpbS6kQ1F1WwsqmZDUTWbiqvZXFJ9REvIaX1SuXJ8X64Y14f+vRID8tqr91Ty5toi3lxbzJaSGlLjYxjSO5khWUkM6Z3E4KxkhvROYlBmUtsHRkc0tnjZVVbH9v217CirZfv+Orbvr2HH/jqKqxrIXjKfvukJ9EtPoF9GAnnpCe52hrsvJT5w67S2eH3srqhnc3E1W0pd0NpaUsPW0lpqGk/uJPGYKOPCWaKHxLgYiisbjgxYh4ky0DfdfVjHNFYxbsTAI0JWdkocSXGB/Qipb/KypaSGDUVVbCyqZmOxe5+VVjeycvcBVu4+tKUlLcFDfbOXppbAtsQdU9n+rnkdP2MgKzmurQUnOyWO7FTXopOd4i4zEmMpqW48JEAXVtSxx3+9zB9AVx0joHmiDZPy0pk29MjAdTzRUcb9n0hPYBqZR2yvb/Kyt7KemoYW6pq81DW5y/omL7VNh95X1+ilrtlLXWMLDS1e0hNj6Z0c1/Y+693uvdcrKbZDXZv1TV5Kqhso8gey4qoGiipdy2FRlbs/LwB/m05FxK8FKSKBV93QzJYDXvZ9sMsfttwH4rGa//ukxTMyN4XUeA/vbixh/b4q1u+r4v/N3cCkAel8cnxfPjGuD9kp8R2uocXr44Md5cxbW8y8tUXsrTzYSB5loKqh5agfygD90hMY3BbMkhjSO5nc1Hj2Hqhn+/7admGrlr0H6g9pAThccZVrjfjoKN0sAKnxMfTLSKRfejz90hPISYvHYPD6fLT4LF6fpcVn8fkv3W0f3nbb6pu8bCt19TR5jx4mMhI9DMtOZlh2MkN7JzOgVyL1za7lp6KumYo6d3mgzrX2VNS6++qavOyvaWR/zcGxO+0D1tG6rXLT4vFEu5Pk3ZiXUR35JztlCbHRnJ6Xxul5aYfcX17bdDCUtQv/lfXu/RjviSIzKY5eSbFkJMWSmeRaADOT3WWvpIM/aQkejKHt2Hu97f49rKXFe/Dfpf2/1apVHzN+/LgO/y7WggV8/v34bOsPh9z2+txjfP5E3Nq6k5MaT1ZyLDHRJ56soH+vRCYPzDjifp/Psr+m0bVQtQtnpdWNjMpNdYFrYPoJuylPRkJsNEN7Jwd8v515/YGZSQzMTApZDSeiACbSQ1lrKa1pbGtl2VJS09bqUlzV+mG9+pDnpMTHtOsGSmVUbgojslNISzzYCtTY4mXBxlJeWbWX+euLWbHrACt2HeAnc9YxdUgmV47vy6Vjc0lPjD2ipoZmLws3lfLm2mLe3lDMgXaBLyc1jpmjc7lkTC5nDelFRV0T20tr2eYPVNtKa9i2v5ZdZXVtXQ+Ltpy4xSLKwIBeiQzKSmJIVhKDMt31wVlJbFz5AaMnncWeCre/vf79Fvpv76mop6qhhSp/4AyEvmnxDPUHrWHZyQzr7S4zk+NOan+NLV4O+ANaTUNL2yBlTwc+2MNFr6RYpg/NYvrQrLb7fD7L/tpGUuI8nWrxPFnePdGcO/yoJ+uHragoQ3ZqPNmp8UweGOpq5HAKYCLdXLPXR1HloeOHWoNWawvC4WJjoshJgMlDc9uC1sjcFPqkxZ9w3FVcTDQzx+Qyc0wutY0tzF9fzKur9rFgUwmLt5axeGsZ3/vPGs4b3psrJ/TlzMG9WLqtjDfXFLNgUyn1zd62fQ3JSmLmmFwuGZPD+Lz0QwZiZ6fEk50Sz1lDDu3+aPb6KKyoZ1tpDdv317K1tJbt+2soqWqkT3o8gzJduBqclcSgrCT6ZyQSG3P0MLI92vhbhY7eVWGtpay2yQUzfygrqW48dIxRVNQhY4oOud9/OzYmioGZiQztnRzwbr24mGhyUqPJSe1462MkiIoynWpRFQk3CmAiEarZ66O03dlQJVUNFFe5M4XcpbuvrLbpmPtIiY85pJWl9ScvI5H3Fi4gP//Upj9Jiovhqgn9uGpCPyrrmnlzbRGvrNrL4q37eXtDCW9vKDniOePy0rhkTC4zR+cwLDu50wPtPdFRbQEr2IwxZCXHkZUcx7i89KC/noh0HwpgImGqrqmFwop6dreeXVTuzi7ac6D+hMGqvSjj5usZ2vvIbq3eKXFBP5OwVVqihxvO6M8NZ/SntLqR11fv49VVe/l4TyWTB2RwyZgcZo7JpW96QpfUIyISSgpgIiHi81n2HHABa3fFwYDVer39oOmjiWo7Q+rg2VGtg3fbnyWVmRwXlAkRT0XvlDjumD6IO6YPCnUpIiIhoQAWAA899BDf+MY3gv4ciUxen2V3uZvfaFNxNVv8l1tLa447kaWnbfxRAv17JbrZpv23+6S507E7coaUiIiEHwWwAFAAEzg4Ienmkho2F1f7L2vYWlpD4zHmKeqdEsfAQ5bxOLisR05qfNi1XImISGB0rwD2xv1QtPrEjzuOBG8LRLc7LLmnw2W/OObjL7vsMsrLy8nPz+dHP/oRv/jFL2hsbMTr9fLHP/6RAQMGcO2111JfX4/H4+HBBx/k+9///iHPOf/880+pZgmdphYf72wo4d8rClmwqfSYQatPWjzDspMZnp3CiJxkhuckM6z3odM3iIhIz9G9AlgIvPHGG+Tm5lJQUMCMGTN44IEHmDp1KmvWrOHrX/86v//976mpqWHhwoVYa9m/f/8hz5HIY61lzZ4qXli+m1dW7T1kctK+afEMz0lheHYyI3JSGJbjBrunBnC2dBERiXzdK4Adp6Wqo+qrq0lJObl17FauXMn999/fdrupqYkRI0bw61//mvvvv5+UlBS+9rWvnXKNEhrFVQ28/NEeXlxRyKbimrb7R+WmcO2kPK6a0JfsbjbXkoiIBEf3CmAhNnr0aP7xj38wePBgAHbs2MGePXsYN24cU6dO5bHHHuOnP/0pDz74YIgrlY5qaPby5toiXlyxh0WbS9uWrMlMiuXKCX25dlIeY/qmdtlUDiIi0j0ogAXAhAkTuPzyy7n00kv53Oc+R3NzMy0tLcyaNYuRI0dyyy23YIyhqamJ3/72t4c855ZbbuHTn/50iH8Dac9ay+YKL3Nf/JjXPt5HtX8RZE+0YeaoHK6dnEf+yN4RtZSLiIiEFwWwAJg7d+5xty9YsKDTz5GuV1TZwIsrCnlheSHb9zcAuwEYn5fGtZPz+OS4vmQkHbl+oYiISGcpgEmP1tjiZf66Ep5fvpuFmw52MabHGW6aOoRrJ/VjeM7JjQkUERE5FgUw6ZHW7q3k+WWFvLxyDwf8ZzF6og2Xjc7luil52L1ruWDGqBBXKSIi3ZUCmPQYFbVN/GflHp5bVsi6fVVt94/uk8oNU/K4akK/ti7Ggn3rQlWmiIj0AApg0q35fJYFm0t5YVkhb60rpsnrJkpNS/DwqYn9uG5yHmP7pYW4ShER6Wm6RQCz1nbbaQCstaEuIWI1tfi47+kVvLm2GABj4PwRvblhSn8uGp1NXEx0iCsUEZGeKuIDWHx8PGVlZWRmZna7EGatpaysjPh4Te7ZWU0tPr44ewXz1xeTGh/D584fyjWT+tEnLSHUpYmIiER+AMvLy6OwsJDS0tKA7K+hoSGsAk98fDx5eXmhLiOiNLZ4+Z/ZK5i/voT0RA9P3nWWuhlFRCSsRHwA83g8bTPPB0JBQQETJ04M2P6kazW2ePnCkyt4Z4MLX7PvPosxfRW+REQkvER8ABNp1dDs5QtPLufdjaVkJHqYffdURvdNDXVZIiIiR1AAk26hodnL555YzoJNpfRKimX23WdxWh+FLxERCU8KYBLxGpq9zHpiOQv94eupe85iVK7Cl4iIhC8FMIloDc1e7vnXMt7bvJ/MpFieumcqI3O1dJCIiIQ3BTCJWPVNLnwt2rKfrGQXvkZo3UYREYkACmASkeqbvNz9rw/575YyspLjePqes7RotoiIRAwFMIk4dU0t3PX4MpZsc+HrmVlnMSxb4UtERCKHAphElLqmFu58/EOWbiund0ocT98zlWHZyaEuS0REpFMUwCRi1DW18Nl/fMj728vJTonj6VlTGdpb4UtERCKPAphEBGstX3p6Je9vLycn1bV8DVH4EhGRCBUV6gJEOuKv721vW1hb4UtERCKdApiEveU7K/h/czcA8ND14xW+REQk4imASVirqG3ivqdW0OKz3H3OYGaOyQ11SSIiIqdMAUzCls9n+frzq9hb2cCE/un876WjQl2SiIhIQCiASdh67L1tvLOhhLQED3+4ZSKxMXq7iohI96BPNAlLy3aU8+CbGwH41fXjyctIDHFFIiIigaMAJmGnvLaJe5/6CK/PMuu8IVw0OifUJYmIiASUApiEFZ/P8rXnVlJU1cDkgRl885KRoS5JREQk4BTAJKz8eeFWCjaWkp7o4fc3T8QTrbeoiIh0P/p0k7DxwfZyfjVvEwC/vmECfdMTQlyRiIhIcCiASVgoq2nkvqdX4PVZPn/+UGaMyg51SSIiIkGjACYh5/NZvvrcKoqrGpkyMIOvzxwR6pJERESCSgFMQu5PBVtYuKmUXkmx/P4WjfsSEZHuT590ElJLtpbx8Ftu3NfDN4ynT5rGfYmISPenACYhU1rdyJee+QifhS/mDyV/pMZ9iYhIz6AAJiHh9Vm++uxKSqsbOXNwL752scZ9iYhIz6EAJiHxt0XbWLRlP5lJsfz+5onEaNyXiIj0IPrUky7X0OzlLwu2AfDgdePISY0PcUUiIiJdSwFMutxLH+2hrLaJMX1TuUDzfYmISA+kACZdyuez/G3RdgDuOXcIxpgQVyQiItL1FMCkSy3YVMqWkhr6pMXziXF9Ql2OiIhISCiASZd67D039usz0wdpwlUREemx9AkoXWbt3koWby0jKTaam84cEOpyREREQkYBTLrM395zY79uOKM/aQmeEFcjIiISOgpg0iWKKht4ZdVeogzcefbgUJcjIiISUkENYMaYe40xS4wxS40xNx62rbcxZo4xZqExZpkx5gvBrEVC6/HFO2jxWS4b24f+vRJDXY6IiEhIxQRrx8aYocCdwFQgDvjAGDPPWlvhf8g3gAXW2l8aYxKBdcaY56y1ZcGqSUKjtrGFp97fCcBd56r1S0REJJgtYBcAr1hrm6y11cBCYHq77UVApv96KlAHNASxHgmR55ftpqqhhckDM5g0ICPU5YiIiIScsdYGZ8fGfAeostb+wX/7Z8Bma+3j/tsxwGvAYCAd+IK19sWj7GcWMAsgJydn8jPPPBOUelvV1NSQnJwc1NcId4E8Bj5r+dbCekrrLfdOiGNKbtAaXQNK7wMdA9AxAB2DVjoOOgbQ+WMwY8aM5dbaKUfbFsxPw1ogrd3tNKCi3e2fAPP9XZCpwOvGmPXW2nXtd2KtfRR4FGDKlCk2Pz8/iCVDQUEBwX6NcBfIY/DG6n2U1q9gQK9EvnpDPtFRkTHzvd4HOgagYwA6Bq10HHQMILDHIJhdkG8Dlxtjoo0xCUA+sMwftgBGAtv916uBSmBoEOuREPirf9mhO88eFDHhS0REJNiCFsCstWuAOcBi4F3gYVwIe9L/kO8CXzLGLAQ+BHYCbwSrHul6K3ZVsHxnBanxMVw/pX+oyxEREQkbQR2QY619AHjgsLtn+7etA84L5utLaP3Vv+zQrVMHkhQXGWO/REREuoImYpWg2F1ex9w1RcREGe6YNijU5YiIiIQVBTAJir//dzs+C1eO70tuWnyoyxEREQkrCmAScJX1zTz34W4A7j53SIirERERCT8KYBJwT3+wi9omL2cPy2R039QTP0FERKSHUQCTgGpq8fH4f3cAcPc5av0SERE5GgUwCajXV++jqKqBYdnJnD+id6jLERERCUsKYBIw1loe8089cfc5g4nSxKsiIiJHpQAmAbNkWxlr91aRmRTL1RP7hbocERGRsKUAJgHzt/fcskO3TRtIvCc6xNWIiIiELwUwCYgtJTW8vaGEuJgobps6MNTliIiIhDUFMAmIv/kX3b5mUh6ZyXEhrkZERCS8KYDJKSuraeTfKwoBuOucwSGuRkREJPwpgMkpe+r9XTS2+LhgVDbDspNDXY6IiEjYUwCTU/bqx3sBuGP6oNAWIiIiEiEUwOSU7Nhfy6biGlLiY5g+NDPU5YiIiEQEBTA5JW+tKwbgglHZeKL1dhIREekIfWLKKWkNYBePzglxJSIiIpFDAUxOWllNI8t2lhMbHaV1H0VERDpBAUxO2tsbSvBZmDY0k5R4T6jLERERiRgKYHLS5q1V96OIiMjJUACTk1Lf5GXRllJAAUxERKSzFMDkpLy3uZSGZh/j+6eTkxof6nJEREQiigKYnJR5/rMfZ6r1S0REpNMUwKTTWrw+3l6vACYiInKyFMCk05bvrKCirplBmYla+1FEROQkKIBJp7VOvjpzTC7GmBBXIyIiEnkUwKRTrLW8tV7TT4iIiJwKBTDplE3FNewsqyMzKZZJAzJCXY6IiEhEUgCTTnlrXREAF56WTXSUuh9FREROhgKYdMrB6SdyQ1yJiIhI5FIAkw7bV1nPx4WVJHiiOWd4VqjLERERiVgKYNJh8/2tX+cOzyLeEx3iakRERCKXAph02Lx200+IiIjIyVMAkw6pamhm6bYyogxcMCo71OWIiIhENAUw6ZCCjaU0ey1nDOpFr6TYUJcjIiIS0RTApENaZ7/X5KsiIiKnTgFMTqipxUfBhhJA00+IiIgEggKYnNDSbWVUN7YwKjeFAZmJoS5HREQk4imAyQmp+1FERCSwFMDkuKy1bQFM3Y8iIiKBoQAmx7V6TyVFVQ30SYtnbL/UUJcjIiLSLSiAyXHNW+tavy46LQdjtPi2iIhIICiAyXG1dT+O0fgvERGRQFEAk2PaWVbLxuJqUuJiOGtwZqjLERER6TYUwOSYWlu/ZozKJjZGbxUREZFA0aeqHNM8TT8hIiISFApgclTltU0s21GOJ9qQP7J3qMsRERHpVhTA5KjeXl+Mz8K0oVmkxHtCXY6IiEi3ogAmR6XuRxERkeBRACyJRAcAACAASURBVJMjNHot720uBeDi0xTAREREAk0BTI6wrsxLQ7OP8Xlp5KbFh7ocERGRbkcBTI6wotgLqPtRREQkWBTA5BBen2VlSQsAM8do8W0REZFgUACTQyzfWUF1MwzMTGR4dnKoyxEREemWFMDkEG+tKwJg5mgtvi0iIhIsCmDSxlrLm2tbp59Q96OIiEiwKIBJm/X7qtlVXkdqLEwemBHqckRERLqtoAYwY8y9xpglxpilxpgbj7J9ojFmsTFmkTFmTjBrkRN7c63rfpyUHUN0lLofRUREgiUmWDs2xgwF7gSmAnHAB8aYedbaCv/2dOAvwNXW2r3GmKDVIh3TGsAm50SHuBIREZHuLZgtYBcAr1hrm6y11cBCYHq77Z8GlgKPGmMWAZ8KYi1yAjv217KhqJqU+BhOy1QAExERCSZjrQ3Ojo35DlBlrf2D//bPgM3W2sf9t/8A9AeuB9KAJcA0a23pYfuZBcwCyMnJmfzMM88Epd5WNTU1JCf3vOkXXt/exHMbm5nWJ5pbh7b0yGPQXk99H7SnY6BjADoGrXQcdAyg88dgxowZy621U462LZjdfrW4YNUqDahod9sLPG+tbQJKjTHLgVHAIQHMWvso8CjAlClTbH5+fhBLhoKCAoL9GuHot+v+CxzgjgvHE79/Y488Bu311PdBezoGOgagY9BKx0HHAAJ7DE7YBWmMedQYM/1EjzuKt4HLjTHRxpgEIB9YZoxJ9W9fBFzof40kYByw6SReR05RUWUDH+06QFxMFOeN6B3qckRERLq9jowBexG42xjzvjHmO8aYvI7s2Fq7BpgDLAbeBR7GhbAn2+230hizDBfWfmStLe5k/RIA8/yTr54/ojeJsToXQkREJNhO+GlrrX0TeNMY4wGuAhYZYzYDf7HWvnCC5z4APHDY3bP923zAV06qagmo1rMfLx2ryVdFRES6QofOgjTGnAH8FvgW8Efgy8Dpxph/BLE26QIVtU0s3VZOTJThwlE5oS5HRESkRzhhC5gx5mNgC/Bna+0X2236gTFmQdAqky4xf30xXp/l3OFZpCV6Ql2OiIhIj9CRAT+/AOZaa8uNMb2BSf5uSYBLg1eadIXWtR8vGaPuRxERka7SkS7Iu6215QD+Obq+1brBWlsfrMIk+GobW1i4uRRjYOZodT+KiIh0lY4EsMNbydRP1U0UbCylqcXHpAEZZKfGh7ocERGRHqMjAWyPMWaWMSbDGPMZoCzINUkXaTv7Ud2PIiIiXaojAexeYBpuLceLgc8HtSLpEo0tXt7ZUAJo/JeIiEhX68g8YGXAZ7ugFulCi7eUUdPYwml9UhmQmRjqckRERHqUjixFdI8xZo0xZlvrT1cUJsGl7kcREZHQ6cg0FJ8H7gQm4tZqnBnUiiTovD7LvHX+6SfG6uxHERGRrtaRMWAHgOXAAGvtu8DU4JYkwfbhjnLKa5sYlJnIyJyUUJcjIiLS43QkgBUDA4HBxpibAPVZRbjW7sdLxuZijAlxNSIiIj1PRwLYV4FC4Lu41q8vHv/hEs6stby5xh/ANP5LREQkJDoyBuwla+10YBvwlSDXI0G2ek8leysbyEmNY0JeeqjLERER6ZE60gK23BgzJuiVSJeY2671KypK3Y8iIiKh0JEAdgew2hhTZIzZZ4zZG+yiJHjaxn+p+1FERCRkOjIRa2pXFCLBt6Wkmq2ltaQnejhzcK9QlyMiItJjnTCAGWO+f/h91tofB6ccCabW7seLTsvBE92Rxk8REREJho4Mwi/2X0YDlwN7gleOBNOba/2Tr6r7UUREJKQ60gX5l9brxpg/Ay8FtSIJisKKOlbvqSQxNppzh2eFuhwREZEerbP9UPHAgGAUIsHV2vqVP7I38Z7oEFcjIiLSs3VkDNg+wAIGaAZ+HuyiJPB09qOIiEj46MgYsDOBcmttrTEmDUgLck0SYKXVjXy4o5zY6CguGJUd6nJERER6vI50Qf4VaPJfrwceDV45Egzz1xdjLUwflklKvCfU5YiIiPR4HQlgcdbaZgBrbRNuHJhEkNbux0vV/SgiIhIWOhLAmluXIjLGjMKNBZMIUdXQzH+37CfKwEWjc0JdjoiIiNCxMWDfAF40xjQCicBtwS1JAundDSU0ey1nDu5FVnJcqMsREREROhbADDAVNxGrAfoHtSIJKHU/ioiIhJ+OdEE+ZK09YK0tA8qAXwa5JgmQhmYv724oBeCSsQpgIiIi4aIjAazttDlrrW1/W8Lbwk2l1Dd7Ob1fGv3SE0JdjoiIiPh1JIBVGWMuBjDG5AONQa1IAmZua/ejWr9ERETCSkfGgN0H/MMY8ziwA7gzmAVJYDQ0e3nLv/yQApiIiEh46UgL2FigDtiEm5D1kaBWJAGxcFMp1Y0tjO6TytDeyaEuR0RERNrpSAvYj3DrP44AioBxQa1IAuLVj/cBcMX4PiGuRERERA7XkRawA8CruBnx/4ECWNirb/Ly9nrX/fjJcX1DXI2IiIgcrkOD8IEMYJQxZiqQF9yS5FS9s6GEuiYv4/un079XYqjLERERkcN0JIB9Djf26yHgfuCHwSxITt2cj/cC8Mlx3aT70VrY/h7MvgF+OQwW/Rpamk78PBERkTB1wjFg1toS/9VlwNXBLUdOVU1jC+9scP9kn4j0AOZthrUvw5Lfw75VkJgF2afB/B/CR7PhEw/BkPwQFyltmmqhZANkDoGEjFBXIyIS1joyCF8iyPx1xTS2+DhjUAZ90iJ08tWGKljxL1j6CFQVQuZwuOI3MP4m8CTApnnwxv/Cv66CMZ+CmT+DtH6hrrpnqiuHjW/Ahjmw9R1oaXD3pw+EPuP9PxPcZXLv0NYqIhJGFMC6mdbuxysicfB9ZaELXSv+BY1VMPAc18o1/BKIatdbPmImDD4PFv8O3vuVC2T534KzvgAxsaGrv6eoLIQNr8H6V2HnYrBeSM2DSXfAwOlQsd21WO5bBetfOfi8lL4uiPWdcDCcpfQBY0L3u4iIhIgCWDdSWdfMgk2lRBm47PQImnx170pY8gdY+5Ib7zXmaph2L/SbdOzneOLh/P+FcTfA3G/DW9933ZKX/xKGnN91tYez2v2w+wPY/T7s3wzJ2ZDeH9IGQFqeu57SB6Kij78fa6F0I2x4FdbPgX0r3f1ZI+Gcr8CoK6DvxKMHqYZKKFp9MJDtWwWb3wTrc9uTekP2aIhLgehYiImHmLh2P/FHuT/etYQm57j6U3IhWiukiUhkUQDrRt5cV0Sz1zJ9aCbZKfGhLuf4vC2uy2rJ72H7QohNhjM/B1M/D+kDOr6fjEFw89Owca6/W/JKGHstzPwppEZgK+DJ8nmhdIMLW7s/cD/lW922KA/0Ggy7lkB9+aHPi4pxxyltgD+c5UFaf0jvT9qB9fDWu657sWyLe3y/KXDRD13oyhp+4rri02DQOe6nVVMtFK/1B7KVLtzVlbnuy5Ym/2Wju/R2ZOUz44Jcah/XynbIZR/3+6X0cbWotU1EwoQCWDcyp3Xy1XDsfmyuhz3LXZfVzsUuIDTXug/Ki3/suq8S0k9+/yMvdS1fi37jzpLc9Cbk3w9nfb57to40VELhMnccCz9w1xur3LbELOh/Fky63V32neBajAAaa1wXYuVu93PAf1lZ6M40rd7b1jo1EVxAG3SOO46jPhGYUBubBP3PdD8nYi14m44MZ001UFMMVXuhet/BywO7YPdSqK84cl/xaW7M4KTboe+k4IQxn8+NW0ztd+KWRZFI4fPCgZ1Et9SFupJuRQGsmyivbeK/W/YTHWXCY+3HhkoXDloD194V7oMUAzljYMItMPhcGHFZ4MZteRJgxrdh/I3wxrdg3nfhoyfhE786tAUmnPi87lg1VrmTD456vfLQ69XFrrULCyYKssfA6de5sNX/TMgYfOxwEZcM2aPcz9F4m12YqSxk9bJFnP6JWaE9o9GYg12PndFc7wJZddHBcFa0BlY9C8sfh5yxLoidfj0k9jq1Gn0+1/K47mVY94oLsXFpMOAsNyZu4NnuRASNT5RIUX8A9iw72JpeuAyaqjkXYEWm+xuTMci1rLe/npx76HhdOS4FsG5i7poivD7LeSN60yspBH/oa/cfDFu7FrtxP9bnWlD6THAtKAPPdh9Kwf5A7zUEbnnOnZ0391vw+BVw8zOulSyUvM2u623Pctizwl3u33hwPNSxeJIgPhXiUl0rTsZA15LT/0zoN9ltC5Roj9t/xkDKdjRH7nQSngT3Pug15ND7L38Q1rwIy//puqznfQ9GX+nC2MBzOv7h4fPCrqUHQ1dNEUTHwbCLYPCXoWSd6/LdPM89PiYB8qa4/wMDp0HeGa4lUCTUrIWyrf7hC/4hDO2/4OWMcWNt+4xn69rlDM0wUL7dtbyv/fehf79i4t0Z0L1aQ9kQ6D3KfeFJygzVbxi2FMC6iVdXhWjy1epiNwD+42fc7Zh49+Fy3jfdt/9QfdAYA6Mud92Sf78EXpoFswqO/EAOFmuhfNvBoLVnORR9fHCahsQsF55GfQKSsvzhyh+w2q6n+wend8Mu1FCJT4Mpd7qffatgxRPw8XOw+nn3TX7S7a51NuUorcg+r/uCse5ldwZoTbF7vw+7yAXiEZe4f6/2akpcENu5BHb+FxY+ePCLSd+JMGBa130xEWm1633YuehgC1fr2ND4NMg7E8Zec/ALXrv39O7qgQzNzz+4H2+z6/av2A4VO1wwq9jhfra/54aZtErp48JczhgXyHLGunGkPfjvmwJYN1BS3cD728uIjY5i5pgu6n70tsCHj8G7P3ehYvp9MOqT7kMlnLpaYpPghifg0Xx49na4ax7EBmF5Jp8XtsyHwg8PtnA1HHDbPImuFfCMu90ftH6T3YkGGhAeWn3GwyfGw8yfuFasFf+Ct38E7/wURlwKk27H+KJh2wJY9x8XumpLXGvWiJkw+io3RUpc8rFfIznbPW70Ve52W9f8f10oW/qIm04lygOX/BzOvCd07wtrXVft/s3upAv/z6SibeC5HSZ/NrCtrdL1fF548zvw/p/d7awR7otq3pluCEPWiM51IUZ7IHOo+zmcte5LSsk61/JfvNYNA9i2AHzN7jFRHn8LmT+Y5Y6FnNN7zJyBCmDdwBuri/BZOG9EFmkJXfBtYucSeP0bULwGhl4Al/0SsoYF/3VPVq/BcO1fYfb1MOer8Kk/B/ZDzueFf8+CNS+AiYac0W4qjb6TXNjqPQqi9V8tbHkS3LjB8TfC/i3w0ROw8inY+BrnmmhY6HUhevhM9+86fObJt+rGp8Hwi90PHDw55b+/gze+6VpJP/Grzo9564yGSn+42npY2Np6aIuFJ9H/wRrlWrkX/grOuAumfsEFy55i5xJY8wK9GvqCPT9yvzg11cGLd8PG12DqF10vxamOfzweY1xLckqu+5xo5W1277vite4zpHgNbF9wsBcFA5f8DKb9T/BqCxP6VOgG2tZ+HB/ksx9rSuCtH8Cqp9zEmzf8C067MjL+IA2/2J0VWfCAG4tz5j2B2a+1MOcrLnzN+K77oxGMFjbpGlnD4OIfwQXfhU1z2bvoGfLOvgGGXRycf1dPgjtBZMB0ePdn8N5DblqOG5+ElJzAvY7PByseh4UPQdWeg/ebKNcamzncdYVmDYPMYe52Sh+IimJFQQH5w1MOnmG85I8w8VbX6n2qXfrNDbCtwM0xV7jMDVsYe53rmg31YO59H8M7P3Hj+EwU46wP9v8Hzv26a+0PZH0tTW66l20Frhs8b0rg9g1QUwpP3+ha5i97EM76XGD33xnRHvclNWc0cP3B+2vLoGQtvP8X10qHgWlfDFWVXUIBLMLtPVDPhzsqiIuJ4sLTAvgHuz1vCyz7u+uaaa6Dc77qvj1F2iDi8/7XtTbM/bbrfurINAjHY637Q7HiX3DuN+D8bwamTgm9aA+c9km2FKeQNzo/+K8XFQUXfs91w/znf1yX+U1PuhbUU1W2FV75khvzM/Bs9+Ujc7gLWr0Gd6y1rd9kuPEJ10K4+Hfu7OLlj8Poq91kvH3Gd7yehkq3esWGV2HzfNfqFpfqpktZ+bT7W5PS141DGntN8KYMOZayre5v3dp/u3GYF/0QJn+WDS8/xKjS1+G5290kxOd+3c05eCqt2xU73AkhHz0BtaWuBf2jJ+Dsr7gvjIFoCd2/GZ681n2Bvmm2G3cajpIy3QonA6bBC3fCm992XxCmfj7UlQWNAliEe321m/vrglHZJMcF4Z9z1/vw+tfdWY1D8uHyhzo2AWc4ioqCax51H27P3Q6fW3hqXSnv/hyW/smd4XnBdwNWpvRgY69xweiZW+Hvl8GVv3NroJ4Mb4tbYaLgAXeG5pW/h4m3nVqYyRrmaprxHffe//DvLqgMvcCFhsHnHX3/1UWw8XW3ksL2hW4MUFI2jLvetSYNPteFjcYa2DTXnan6/l9c/RmDXdA5/TrIPu3kaz+Ryj2w4P+5cBkT575UTb+vbX7Coj4XMerGH7kVO9572J3YU/Bz93tPuKXjYcnb4lrVlv3djRs1xo05nHKna/ma911Y9LCby/BTj3Qu3B5u52J45hZ30sdnXoO8AAT6YIv2wHV/h+c/485iN1Fw1qxQVxUUCmAR7tVgTb5aUwrzfwgrn3STSl7/TzeQOBK6G48nIcMNyv/bxe5b1m0vn9w32P/+1p3RNvHTcMkDkX9cJHz0GQez3nUfQC99zn35uehHnXuf7vsYXrnXnek56gr3xSk1gGdIp+S6CZTP+ZoLEksfcatQ9J3oWshHXeFadzbMcaGr8EPAujA19fMudOWdcWQ3XlyyC1qnX+cm010/x3XvL3rYdc9mj3ZhbOy1rvUuEGrL3P4/eMydoXrG3XDeN47+5Swq2tU25hoXFBf+0g1BWPAgnP0lN6H0sbqqq/a6s25X/NN1A6f0ccupTbrdrUDR6qo/uqEdr9wHj13gehvO/XrnzxZc8yK89Hk3LcStzwfueHWFaA9c9w944bNubKQxgRs2EkYUwCLY7vI6Vu0+QGJsNBeMCtCgWG8zffe8Dktvd0vGnP0V9wfgeGd6RZo+4+CK38DLn3dnvc38Seee/+Ff3aDkMdfAJ38X+rEq0v0kZcFtL7ku7iV/cGeSXff3E09V0dzgvhgs+g0kZgb/i1NCOpz7NTeoe9XT7ovJc7e7rrvWs4Bzx0H+t+G0K1yA6mgtCRkw6Tb3U13szkRd84Ibl/XOT1y36Oir3T7T+7sltDozTq+x2o1nW/wH1w067ibX7Zcx8MTPjYpyZw+OvAy2vetOUJh7vxtjN+2LcMY97oxRn89tX/Z3Ny+h9cLQC904rBGXHjtUj7gEvrjUzVVX8IBrPfzUXzrWAmgt/Pc37gv0gGlw01PBHWwfLDGxLoQ9f4c76csYF467EQWwCPaqf/D9RaflkBB7isueFK91i1l//Cwj6va7roTLH4LeIwNQaRiacLOb6Xnx79wf8jFXd+x5q56B177uZvC/5lEtNyPBE+1xi8vnjHXvuccugJuePvYqBjuXuFaTss0w4Va3HmpXffB64mHKZ11rzvpXXMtV6zx3HQk0J5KS47qhzprl5p1a82/XwvPW9w59XGKmC2Jpee7kAv+6pu6+/u54tDS6L1GLHnZrkJ72SXcCzbGO6/EY47pfh17gjv97D8HbP4ZFv4Wxn3KD6it2uHn/pt8Hk+/o+IkLib3c2dunfRLmfA3+cp7r+p3+pWP/3fG2uBajZX93XxCvfsT920SqmFj3JeK5293/ARPlumq7CQWwCDZnVWv340l2LdSVuwkoV852XRVRHhh5KR/HTGDcNV/v/t1qlzzgfu///I/7ZnmisLnuFXj5CzD4fLj+8R49gaB0ocl3uPfms7fBXy+Eax5zrS+tGqpcS+6Hf3Wh49P/hmEXhqbWqGg3Ke2YTwXvNdIHuIH/53wFqva5gFO52wWz1nVO92+Gre+4k4ba8yS5/7cNB2DIDHfiQyBOdAC3wsHAF2HvR/Der9zg+oFnwwXfcyHqZAfUj77KnSX72lddq9aG112wOnzqn8YaN6xi85uu5+LCH3SP1vmYWLjhn+79P+erLoRN/kyoqwoIBbAIta20hnX7qkiJi+H8kZ2YtM7b4gZ+rpztmsR9zW6Q52UPutO/kzIpLyjo/uELDn67+st58Oyn4Z53jpzJvNXm+e6PW94Zrkk/kr9VSuQZMNWt5PDsrfDMza7F5rxvwOa33IdS1R7XDTjj/7rXcIETSe3jH9s27cht1rpxZAd2tVt4vtDdN/4mt0pGMPSd6KYR8bYEbv6/5N5u7OrqF1x33J/PgYt+AGd+zoWs6iJ46gY3XvATD7v52rqTmDh3Fu6zn4ZXv+xC2KTbQ13VKVMAi1Bz/IPvZ47JJS6mA91gJetd6Fr1rJvNOzELzpzlzt7JHRvkasNYWj+4/h/wr6tcS9j1/zwyfO5Y5D74sk9za0z2pA84CR9p/eCzb7gPoHd/6lqv9290E/3eNe/Up1Xpboxx3XiJvdwUF10t0JMvG+POGh10Drz6JTfmbP0c1xI456uuR+PmZ9z4se4oJs6F0GdvddOqYNz4wJPRWO26jPtNcuMtQySoAcwYcy9wK2CAX1trnz3KY+KBD4EXrbU/DGY93Unr2o9XjD9O92NLkzvjZuVs1yweFeMGfk641U1Mqi40Z/B57iyzt77nBjxPv+/gtsLl8NSN7kyi215qOyVdJCQ8CW4wdu7p7sy78+93g+CDOXO+hJfUPu6L4EdPujkNZ18HyTnw2ddc61t35omHG2e7VuBX7nMtYRNvPfHzmurcQuM73nPToOxZ4U6IuPoR1wgRIkELYMaYocCdwFQgDvjAGDPPWltx2EN/DMwPVh3d0caiajaX1JCe6OGcYcdJ7+/+zJ0Nk3s6XPoLOP36kKb9sDb9Pneq/Fs/cOs2glu37Mlr3MDe21/WsZPwYIx7v067t2cMFZAjGX/rz5B8WPY3NzA9fUCoq+oanng3DOTpm12vhYlyJ1W119LoVlbYvtCFrsIPwdvkJrrtN9m1Gg4+z61/GULBbAG7AHjFWtsENBljFgLTgddaH2CMOQvIBh4H8oNYS7fSuvTQZWNz8UQfY5Bl1V634Oq4G93ZenJ8xsDVf3Jnmr3wWdKHfQme+J1bD++OVyA1yMs8iXSWwpek93cz9fc0ngS4+Wl4+iZ3YpT1uYXEty9wgWvX+9BSDxg3xvmsz/tn2Z967HG+IWCstcHZsTHfAaqstX/w3/4ZsNla+7j/dhzwOnAdMB7IP1oXpDFmFjALICcnZ/Izzzxz+EMCqqamhuTk8B3jY63l/vfqKa6z/O8Z8YzOPPr4rxEb/0Ru0dt8cOafaEjo3BJF4X4MgimxdjeTVnyDGG8DTZ40Vk74OXVJeSd+YjfUk98HrXQMdAxa6TiE3zGI8jZy+uqfknHg47b7apIGciB9HBUZp1OZNoYWT2Dr7ewxmDFjxnJr7VEX9wxmC1gtkNbudhrQvvvxR8DD1toKc5xvctbaR4FHAaZMmWLz8/MDX2k7BQUFBPs1TsWaPZUUv7mIrORYZl09g5ijtYCVbYWFb8OUzzL1shs7/RrhfgyCbkgGNXP+j+TbnuTM3NNDXU3I9Pj3AToGoGPQSschTI/Buee6sc4puTDoXJKTskgGgvW1OZDHIJgB7G3gL8aYXwCxuC7GB4wxqdbaKuB0YJAx5jagH5BhjCm21j4SxJoi3qtt3Y99jh6+wK1RGB3rZrCXzjvtCpYVJ5Pfg8OXiEhEiE2EqV8IdRUnJWgBzFq7xhgzB1gMWOBhXAi7EbjSWtu2JLsx5jPAIIWv47PW8pp/+olPjj/GmKSi1W65jnO/7maPFhERkbAT1GkorLUPAA8cdvfsozzu8WDW0V2s3H2Awop6clPjmTLwGGvCvf0Ttw7b9C91bXEiIiLSYd1gnYKe41X/0kOXn96HqKijjJvbtdQtQ3HOVzRflYiISBhTAIsQPp/l9dX+tR+PNvmqtTD/R5Cc65anEBERkbClABYhlu2soKiqgX7pCUzsf5TWrS3zYddiOP+bblCiiIiIhC0FsAjxyqo9gGv9OmLaDp/PtX5lDIKJkb9AqYiISHenxbgjQF1TC/9Z6aafuHpCvyMfsPbfULwarnkMYmK7uDoRERHpLLWARYA5q/ZR3dDCxAHpnNYn9dCN3ma35mP2GBh7XWgKFBERkU5RC1gEmP3BLgBuOfMoi61+9CSUb4Obn4Eo5WkREZFIoE/sMLd2byWrdh8gJT6GK8YdNvlqcz0s+H+QdyaMuDQ0BYqIiEinqQUszD31vmv9unZSHgmxhy28/cFjUL0Prv0bHGc9TREREQkvagELY7WNBwff33LWYd2PDZWw6GEYdhEMOjsE1YmIiMjJUgALY6+s2ktNYwtnDMpgRE7KoRsX/wHqK+DC74emOBERETlpCmBhrLX78YjWr5pSWPJHGPMp6DM+BJWJiIjIqVAAC1MfFx5g9Z5K0hM9XDb2sKWH3nsIWhpgxndDU5yIiIicEgWwMNV+8H28p93g+wO7YNnfYeKtkDUsRNWJiIjIqVAAC0PVDc28ssoNvr/58Lm/Cn4BGDj//q4vTERERAJCASwMvbxyL3VNXs4a3Ith2ckHN5RsgFVPw5n3QNpRliQSERGRiKAAFmastW3dj7dOHXjoxnd/Cp4kOOdrIahMREREAkUBLMys3H2A9fuq6JUUyyVjcg5u2PoOrH8Vpt8LSZmhK1BEREROmQJYmGlt/bp+ch5xMdFgrZvz68nroNdQmPY/Ia5QRERETpWWIgojlfXNvPpxu8H3DZXw8hdhwxwYdQVc/SeISznBXkRERCTcKYCFkZdWFNLQ7OPsYZkMatkGj94OFTth5k9h2r1a71FERKSbUAALE9ZanvrAdT/+b85y+OuPIT4dPvMaDJwW4upEREQkkBTAwsTynRXsLC7nNwlPMH75ThQmiwAAEVBJREFU2zD4PLj2b5CcHerSREREJMAUwMLEm+8t4d+xP2CM3QnnfgNmfAeiok/8RBEREYk4CmBhoHbVy9y35Qv4jKH0k0/Qe/KVoS5JREREgkjTUISStxnmfZekl+5gu83lx/3+rPAlIiLSA6gFLFSq9sELd8KuxfzHcxnfrL6J300/M9RViYiISBdQAAuFfavcxKpNNWw+59d8eX4O2SlxXHiaBtyLiIj0BOqC7Gr1B+DZT0N0LNzzLr8vnQjAjWf0xxOtfw4REZGeQJ/4XclaeOVeqNoL1z9OedIQ5q4pIsrATWcOCHV1IiIi0kUUwLrSB4+6BbUv/AH0P4MXlu+myesjf2Q2/dITQl2diIiIdBEFsK6y9yOY910YcSlMuxdrLU9/sBuAW9T6JSIi0qMogHWFhkp4/jOQlA1XPwJRUSzZWsb2/bX0SYsnf2TvUFcoIiIiXUhnQQabtfDKfXBgN3z2DUjsBcBs/7qPN57RnxgNvhcREelR9MkfbB/+Fdb9By78Pgw4C4DS6kbe9A++v/GM/iEuUERERLqaAlgw7VsFb34Hhl0M07/Udvfzy3fT4rNcMCqHPmkafC8iItLTKIAFS0OVG/eVmAWf+gtEuUPd1OLjX4t3AnDrVA2+FxER6Yk0BiwYrIVXvwwVO+EzcyAps23TK6v2UlTVwIicZM4frsH3IiIiPZFawIJh+T9g7b/hgv+DgdPb7rbW8ujCrQDMOm8oUVEmVBWKiIhICCmABVrRanjjfhh6IZz91UM2FWwsZVNxDbmp8Vw5vm+IChQREZFQUwALpMZqN+4rIeOQcV+t/rzAtX7ddc5gYmN06EVERHoqjQELFGthzlf/f3t3H2RnWd5x/Htlk2xeNm+QZIVAeCcICIYkYkHCQiqdomJj1TjiIG9F6zh1Sqe21emMjrW2doZR2zoFBCMtNrzoUESlKkoCJkA2EkOCUIQQSEgCCQkkG9hks1f/OGdl2XMWSbLnOdk9389MhpznPrN75Zqb3d/ez73PDS8+BR//AbS8fn/Xw89s48G1LzJu1HA+8g4fPSFJUiNzGWag/OomeOQ2aPscHP2uiuHrljwFwMfeeRTjRo0oujpJknQQMYANhM1r4MefhWPb4JyrK4bXbung7jWbGNk0jMvOOrro6iRJ0kHGAHagOnfCrR+HURPgA9fDsKaKt1x/31NkwgfOmMbU8aPqUKQkSTqYuAfsQC39V9j6W7jkf6BlasXwCzs6uX3FegCuPOfYoquTJEkHIVfADsTePbBiIRw/D449t+pbvrP0aXZ3dfPuk1s5fmpLsfVJkqSDkgHsQDz+I9i5CWZfUXW4o7OLm5Y9DcAnz3X1S5IklRjADsTyG2D8EXDiH1UdXrT8WV5+tYvZR01i1lGHFFycJEk6WBnA9teW38LaxTDr0qob7/fs7eaG+0qPnvjEuccVXJwkSTqYGcD2V/uNMGw4nHFJ1eG7Vj3Hcy+9ynFTxjLvpMrN+ZIkqXEZwPbHnldg5c3w1vfBuNaK4czk2sXl1S8P3ZYkSX0YwPbH6u/Dq9v73Xy/5IktPLZpB1PHNfP+mR66LUmSXs8Atj/ab4DJM6oeOQRwbfnQ7cvfdQzNwyv3h0mSpMZmANtXz62EDStg9uUQlbcWV63fztInt9LSPJyPnjm9DgVKkqSDnQFsX7XfACPGwOkfqTp8bfnQ7Y+eOZ3xHrotSZKqMIDti1dfgkduh1P/FEZPrBhet7WDHz+ykRFNwWVnH118fZIkaVCoaQCLiE9HxLKIeCAiFvQZmxIRN0fEgxHRHhGfrmUtA+LXi2DPLphTffP9t+5bS3fC+98+jcMmjC64OEmSNFjU7DDuiDgOuBx4J9AMPBQRP8nMbeW3TAW+kpmrI2I0sDYi/j0zs1Y1HZDM0pPvDz8DDp9ZMbx1Zye3tj8LwFVzPXZIkiT1r5YrYOcDd2bm7szcASwBzuoZzMw1mbm6/PJQYP1BG74A1v0Stjze7+rXd5ato7Orm3knTeXE1nEFFydJkgaTqFXmiYjPAS9n5r+VX38ZeCIzF/Z531jgB8DVmbmyyse5CrgKoLW1ddaiRYtqUm+PnTt30tLSUnH95DX/wqRtD7PsD75Nd1Pz68Y6u5KrF++iYw/83TtGMeOQwf3oif560EjsgT0AewD2oId9sAew7z0477zzVmTm7GpjNbsFCXQAE3q9ngBs6/2GiBgH3Ap8sVr4AsjM64DrAGbPnp1tbW01KbbHvffeS8Xn2Pk8LHkQ3vFnzJ1XefD2wl+upWPPo8ycPpGr5p9FVHk8xWBStQcNxh7YA7AHYA962Ad7AAPbg1regrwHuDAimsp7vNqA9ogYDxARE4A7gH/OzMU1rOPA/eom6N5TevZXH117u7n+vrVA6dihwR6+JElS7dVsBay8uf4uYCmQwDWUQtgC4CLg88BJwBd6hZaLM3NDrWraL917YcVCOGYuTD6hYviHj2xkw/ZXOGbyWN59cuW5kJIkSX3V8hYkmfkV4Ct9Lt9cHvss8Nlafv4B8cRP4aVn4YJ/qDq8cOnTAFx5zjE0eei2JEl6E3wQ6+/TfgO0vAVOek/F0BObd/DwM9tpaR7O/JnT6lCcJEkajAxgb2Tb06UVsDMugabKY4VuWV567tf7Tj+cMSNrupgoSZKGEAPYG2n/NsQwmHVpxdDurm6+/3Bpu9qCOUcWXJgkSRrMDGD96eqEh/8TZvwxTKi8vfiz32zmxY7dnPSWcZx+xIQqH0CSJKk6A1h/Hr0Tdm2t+ugJeO3244dnH+mjJyRJ0j4xgPWn/QaYdAwce17F0Ibtr7DkiRcY2TTMzfeSJGmfGcCq2bwGnllWWv0aVtmi29vXkwkXnNLKpLEj61CgJEkazAxg1bTfCE3NMPNjFUPd3cltK0q3H918L0mS9ocBrI+mrlfg17fAKfNhzCEV40uf3Mr6ba8wbeJozj5uch0qlCRJg50BrI+pzy+G3TtgzhVVxxctfwYobb4f5pPvJUnSfjCA9ZbJtA13Q+vb4Ig5FcPbOnbzkzWbiYAPzj6iDgVKkqShwADW2/rltHSshTmXQ5VHS9yxcgO793ZzzglTmDZxdB0KlCRJQ4EBrLdNq9gzfBy87cMVQ5n5u2d/fcTN95Ik6QB4gGFvc65k2ctHMre5pWJo1fqXeGzTDg4ZO5I/fGtrHYqTJElDhStgfXQ3NVe9fkt7afVr/sxpjBxu2yRJ0v4zSbwJu3Z3cefK5wCf/SVJkg6cAexN+NEjm9jZ2cXM6RM5sXVcvcuRJEmDnAHsTbi1vPl+wWxXvyRJ0oEzgP0eT76wk4eefpExI5t47+mH17scSZI0BBjAfo9by5vv33vaYbQ0+0ujkiTpwBnA3sCevd18b8UGwM33kiRp4BjA3sAvHnueLTs7OX5qC2dMn1TvciRJ0hBhAHsDt/TafB9VjiaSJEnaHwawfmx++VV+8fjzDB8WzD9jWr3LkSRJQ4gBrB+3r1hPd8K7T25lckv1p+NLkiTtDwNYFd3d+bvffvywm+8lSdIAM4BV8eDaF1m3dReHTRjF3BOm1LscSZI0xBjAquhZ/frQrCNoGubme0mSNLAMYH107El+9MhGAD7k0UOSJKkGDGB9PLCxi86ubs4+/lCOPGRMvcuRJElDkAGsjyXruwBYMGd6nSuRJElDlQGsl9UbXmLdy91MGD2CC05urXc5kiRpiDKA9dKz+X7+zGmMGtFU52okSdJQZQDrZcvOTsCDtyVJUm0ZwHr55sWzuKZtNG89bHy9S5EkSUOYAayPQ0bZEkmSVFumDUmSpIIZwCRJkgpmAJMkSSqYAUySJKlgBjBJkqSCGcAkSZIKZgCTJEkqmAFMkiSpYAYwSZKkghnAJEmSCmYAkyRJKpgBTJIkqWCRmfWu4U2LiBeAdTX+NJOBLTX+HAc7e2APwB6APQB70MM+2APY9x4clZlTqg0MqgBWhIhoz8zZ9a6jnuyBPQB7APYA7EEP+2APYGB74C1ISZKkghnAJEmSCmYAq3RdvQs4CNgDewD2AOwB2IMe9sEewAD2wD1gkiRJBXMFTJIkqWAGsF4i4tMRsSwiHoiIBfWupx4iYntE3NvrT0u9aypCRMyIiKURsajXtS+Xry2LiLY6lleIvj2IiKMjYlOvuXBXvWuspYgYGxHfjIiHImJ5RPxj+XrDzINqPWjAeTAxIm7t9b3g6vL1RpoHFT1otHnQI0p+GhELy68HbB4MH4gCh4KIOA64HHgn0Aw8FBE/ycxt9a2scCszs63eRdTBmcA3gD8BiIjzgbdn5lkRcTjw84g4NTO76llkjb2uB2V3Z+al9SmncBOB72bmpyJiGPCbiFhNY82Dih4Ad9JY86AZ+EJmPhoRwynNg/U01jyo6AGwhMaaBz0+BawGJg309wVXwF5zPnBnZu7OzB2UJttZda6pHk6JiCXlP1fUu5iiZOZNwKZel+YBt5XHnqP0AOAZdSitMFV6ADAvIu6PiJ9HxEX1qKsombkhM+8vvxwL7AZm0UDzoJ8ebKex5sHmzHy0/HIK0EXph5NGmgfVetBBA80DKN0FAC6k9IMpDPD3BVfAXjOF1z/ddkv5WqNpzczuiDgU+GFEPJ2Z99S7qDqYAizr9boR58M6YHpmZkRMB34aEY9n5uP1LqyWIqIJuAn4a+ADNODXhT49eJzGnAf/BFwF/A0wh8acB7178BgNNA8iIigFr78Aen5bcUC/L7gC9poOYEKv1xOARrv9SGZ2l/+7FfgecHp9K6qbhp8PWVb++zPAz4BT6ltVbUXECOC/gEWZeTcNOA/69qAR5wFAZv4tcCRwCXACDTYPoKIHcxpsHnwS+N/MfLLXtQH9emAAe809wIUR0RQRo4E24MH6llSsiDgqIiaW/z4aeB9wX32rqpt7gIsAImIypWXmIfmTXn8i4sTyPCAiJgHnAMvrW1XtRMRIYBGlrQi3lC831Dyo1oMGnAczIqJnVWMX8BLwNRprHlTrwcxGmgeUVj3nln8p6T+AcymFrQGbB96CLMvM1eXf6lhKabnxmszsux9mqBsPLCzffhgBfCszh/L/YG/kh8AFEbGU0g8qn8nMV+tcU9EOB26MiL2U5sPnM/PZOtdUS1dS+sHr0Ij4RPnaXwGbG2geVOvBD4D5DTQPuoBrI2ICMAa4n9IvIsxroHlQrQf/R+m2Y0PMg8y8vOfv5d92vBT4EvD1gZoHPohVkiSpYN6ClCRJKpgBTJIkqWAGMEmSpIIZwCRJkgpmAJMkSSqYAUySJKlgBjBJ6kdENNqzACUVxAAmSZJUMJ+EL2nQi4hhwFeBMyl9XfsuMAvYAZwKTAJuzMxvRMS7KD3ROoFO4C8z87GIOB/4IrCX0plvC8of+0vAXKCZ0uHcTZSO6+kGXgE+mZlPFfRPlTRE+CR8SYNeRFwKnJmZf14OY/dTOsNuVWZeHRFjgFWUzq9bAszNzI0RcRrwTeBCYCVwTmZuiIhxlMJZJ9CWmYsj4u/LH3Ml8Cngg0ALMLJ8eL0kvWmugEkaCmYDZ0fEveXX44GdwF0AmbkrItYARwIdmbmxfH1VRBwLnAisycwN5es7ACJia2YuLn/MZ4EZmXlPRAyndEDzeuDrRfwDJQ0t7gGTNBSsBm7LzLbMbAPeC2ykdPuRiBgPnAL8FhgbEYeVr58GrC1fPzUiWnveHxGjKR1K3FtExNHAzzPzM8BESgdYS9I+cQVM0lBwPfC1iLiP0h6ujcBuYG5EvAeYDHwhM1+MiMuA/46IbkoB68rM3B4RnwHuiIjdwMvAxf18rpOBm8vvGwZcVtN/maQhyT1gkoakiFgILMrMu+tdiyT15S1ISZKkghnAJEmSCuYtSEmSpIK5AiZJklQwA5gkSVLBDGCSJEkFM4BJkiQVzAAmSZJUMAOYJElSwf4fzS4b1n4zqdMAAAAASUVORK5CYII=)![model2.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "aKM42-PbJKzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##내 이미지로 찾기"
      ],
      "metadata": {
        "id": "OgmGuRZmwZD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfj0amdXp8KH",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "a156e9d6-e571-4bdb-87f3-07c7b9b14740"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08660dad-2be9-4527-aadf-193af3a473aa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08660dad-2be9-4527-aadf-193af3a473aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ddfc5d1dbe5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m   \"\"\"\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    116\u001b[0m   result = _output.eval_js(\n\u001b[1;32m    117\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m--> 118\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m    119\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "      name=fn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql3mNzdGp9YK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "img=mpimg.imread(name)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQNrCd1vqGzw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "img = cv2.imread(name)\n",
        "img = cv2.resize(img,(128,128))\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6BD9OLKpZlf"
      },
      "outputs": [],
      "source": [
        "y_hat0 = model0.predict(img[np.newaxis ,:,:])\n",
        "#print(y_hat0)\n",
        "category = categories[y_hat0.argmax()]\n",
        "print('model0(기본) 판정 : ',categories[y_hat0.argmax()])\n",
        "\n",
        "y_hat1 = model1.predict(img[np.newaxis ,:,:])\n",
        "#print(y_hat1)\n",
        "category = categories[y_hat1.argmax()]\n",
        "print('model1(은닉층) 판정 : ',categories[y_hat1.argmax()])\n",
        "\n",
        "y_hat2 = model2.predict(img[np.newaxis ,:,:])\n",
        "#print(y_hat2)\n",
        "category = categories[y_hat2.argmax()]\n",
        "print('model2(레이어) 판정 : ',categories[y_hat2.argmax()])\n",
        "\n",
        "# y_hat3 = model3.predict(img[np.newaxis ,:,:])\n",
        "# #print(y_hat3)\n",
        "# category = categories[y_hat3.argmax()]\n",
        "# print('model3(inceptionV3) 판정 : ',categories[y_hat3.argmax()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##해당 위치 나타내기"
      ],
      "metadata": {
        "id": "C9aWjk_GwlCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import pandas as pd\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "mc = MarkerCluster()\n",
        "file = \"/content/drive/MyDrive/location.csv\"\n",
        "df = pd.read_csv(file, encoding='cp949')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PV4re1z3U7i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =df.groupby('theme').get_group(category)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ruG28UDNSHvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#마커\n",
        "map = folium.Map(location = [33.3080, 126.57423], zoom_start=10) #제주도 서귀포시로 열기\n",
        "\n",
        "for name in df.index:\n",
        "  lat = df.loc[name, 'Latitude']\n",
        "  lng = df.loc[name, 'Longitude']\n",
        "  mc.add_child(\n",
        "      folium.Marker(location=[lat, lng],popup = df.loc[name,'name'],tooltip = df.loc[name,'name'])\n",
        "            \n",
        "  )\n",
        "map.add_child(mc)\n",
        "map"
      ],
      "metadata": {
        "id": "R66x_ETiKbxs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VgRGXyHVuMpl",
        "EIfetCoM2m77"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}